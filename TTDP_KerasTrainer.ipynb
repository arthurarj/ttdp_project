{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "%run utils/utils_keras.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Lambda\n",
    "from keras import optimizers\n",
    "from keras import metrics\n",
    "\n",
    "from time import time\n",
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks = 100\n"
     ]
    }
   ],
   "source": [
    "file_indices = [i + (616 if i>260 else 0) for i in range(696)][:100]\n",
    "n_files = len(file_indices)\n",
    "print('Number of chunks =',n_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data at once (only for limited dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for chunk_id in file_indices:\n",
    "    data = data.append(pkl.load(open('../data/processed_chunks/processed_ttd_chunk_{}.p'.format(chunk_id), 'rb')))\n",
    "\n",
    "#data.drop(data[data.vec_dist > 15].index, inplace=True)\n",
    "\n",
    "# Drop trips with distance exceeding 40 miles\n",
    "data.drop(data[data.trip_dist > 40].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guarantees indices to be unique, which is important for random permutation\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(data)\n",
    "train_p = 0.7\n",
    "valid_p = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5588180000000023"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Square box around NYC\n",
    "LAT_NORTH = 40.976897\n",
    "LAT_SOUTH = 40.418079\n",
    "LON_EAST = -73.700272\n",
    "LON_WEST = -74.259090\n",
    "assert LAT_NORTH-LAT_SOUTH == LON_EAST-LON_WEST\n",
    "RANGE = LAT_NORTH-LAT_SOUTH\n",
    "RANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 5*1e-4\n",
    "data['pu_lon_n_q'] = data.pu_lon_n.apply(lambda x: np.floor(x/step))\n",
    "data['pu_lat_n_q'] = data.pu_lat_n.apply(lambda x: np.floor(x/step))\n",
    "data['do_lon_n_q'] = data.do_lon_n.apply(lambda x: np.floor(x/step))\n",
    "data['do_lat_n_q'] = data.do_lat_n.apply(lambda x: np.floor(x/step))\n",
    "\n",
    "1/(5*1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea of treating input as image\n",
    "\n",
    "# def get_gaussian(gauss_kernel = 5):\n",
    "#     x, y = np.meshgrid(np.linspace(-1,1,gauss_kernel), np.linspace(-1,1,gauss_kernel))\n",
    "#     d = np.sqrt(x*x+y*y)\n",
    "#     sigma, mu = 1.0, 0.0\n",
    "#     return np.exp(-( (d-mu)**2 / ( 2.0 * sigma**2 ) ) )\n",
    "    \n",
    "# g = get_gaussian()\n",
    "# print(g)\n",
    "\n",
    "# N_SAMPLES = 400#len(data)//10000 #100\n",
    "# image_data = np.zeros((N_SAMPLES,2000,2000,1))\n",
    "\n",
    "# for index, row in data[:N_SAMPLES].iterrows():\n",
    "#     image_array = np.zeros((2000,2000))\n",
    "\n",
    "#     pu_lat = int(row.pu_lat_n_q)\n",
    "#     pu_lon = int(row.pu_lon_n_q)\n",
    "#     do_lat = int(row.do_lat_n_q)\n",
    "#     do_lon = int(row.do_lon_n_q)\n",
    "        \n",
    "#     gauss_kernel = g.shape[0]\n",
    "#     image_data[index, pu_lon-gauss_kernel//2:pu_lon+gauss_kernel//2+1, pu_lat-gauss_kernel//2:pu_lat+gauss_kernel//2+1, 0] = g    \n",
    "#     image_data[index, do_lon-gauss_kernel//2:do_lon+gauss_kernel//2+1, do_lat-gauss_kernel//2:do_lat+gauss_kernel//2+1, 0] = -g    \\\n",
    "\n",
    "# plt.figure(figsize=(16,16))\n",
    "# plt.imshow(image_data[10,:,:,0],cmap='gray')\n",
    "# #plt.xlim((1000,1250))\n",
    "# #plt.ylim((900,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_pu_lon_n = 0.42\n",
    "# max_pu_lon_n = 0.47\n",
    "\n",
    "# min_pu_lat_n = 0.58\n",
    "# max_pu_lat_n = 0.60\n",
    "\n",
    "# block_data = data[(data.pu_lon_n < max_pu_lon_n) & \n",
    "#                   (data.pu_lon_n > min_pu_lon_n) &\n",
    "#                   (data.pu_lat_n < max_pu_lat_n) &\n",
    "#                   (data.pu_lat_n > min_pu_lat_n)]\n",
    "# #block_data = data\n",
    "\n",
    "# step = 5*1e-4\n",
    "# block_data_pu_lon_n = block_data.pu_lon_n.apply(lambda x: np.floor(x/step)*step)\n",
    "# block_data_pu_lat_n = block_data.pu_lat_n.apply(lambda x: np.floor(x/step)*step)\n",
    "\n",
    "# #long_trips = block_data[block_data.vec_dist > 15]\n",
    "# #np.floor(data.pu_lon_n/step)*step\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(12,12))\n",
    "# plt.scatter(block_data.pu_lon_n[:100000],block_data.pu_lat_n[:100000],s=1)\n",
    "# plt.scatter(block_data_pu_lon_n[:100000],block_data_pu_lat_n[:100000],s=1,c='r')\n",
    "\n",
    "\n",
    "# # for i in range(0,len(long_trips),1):\n",
    "# #     #if long_trips.iloc[i].original_index != 5173594:\n",
    "# #     #    continue\n",
    "# # #        print('OPA')\n",
    "# #     plt.plot((long_trips.iloc[i].pu_lon_n, long_trips.iloc[i].do_lon_n),\n",
    "# #              (long_trips.iloc[i].pu_lat_n, long_trips.iloc[i].do_lat_n))\n",
    "# #     plt.scatter(long_trips.iloc[i].pu_lon_n, long_trips.iloc[i].pu_lat_n,s=50, c='k')\n",
    "# #     plt.scatter(long_trips.iloc[i].do_lon_n, long_trips.iloc[i].do_lat_n,s=50, c='r')\n",
    "\n",
    "# #plt.scatter(data.pu_lon_n[:400000],data.pu_lat_n[:400000],s=1)\n",
    "# plt.xlim((0.45,0.47))\n",
    "# plt.ylim((0.58,0.6))\n",
    "\n",
    "# #plt.xlim((min_pu_lon_n,max_pu_lon_n))\n",
    "# #plt.ylim((min_pu_lat_n,max_pu_lat_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split samples (save and/or load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_samples_ids, valid_samples_ids, test_samples_ids = np.split(np.random.permutation(data.index),\n",
    "#                                                                   [int(n_samples*(train_p)),\n",
    "#                                                                    int(n_samples*(train_p + valid_p))])\n",
    "\n",
    "#samples_ids = {'train_samples_ids':train_samples_ids, 'valid_samples_ids':valid_samples_ids, 'test_samples_ids':test_samples_ids}\n",
    "#np.save('samples_split_ids.npy', samples_ids)\n",
    "#samples_ids_check = np.load('samples_split_ids.npy')[()]\n",
    "\n",
    "#assert np.all(samples_ids['train_samples_ids'] == samples_ids_check['train_samples_ids'])\n",
    "#assert np.all(samples_ids['valid_samples_ids'] == samples_ids_check['valid_samples_ids'])\n",
    "#assert np.all(samples_ids['test_samples_ids'] == samples_ids_check['test_samples_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_ids = np.load('samples_split_ids.npy')[()]\n",
    "train_samples_ids = samples_ids['train_samples_ids']\n",
    "valid_samples_ids = samples_ids['valid_samples_ids']\n",
    "test_samples_ids = samples_ids['test_samples_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# plt.subplot(211)\n",
    "# plt.hist(data.duration, bins='auto', log=True)\n",
    "# plt.xlim(0,7300)\n",
    "# plt.subplot(212)\n",
    "# plt.hist(data.trip_dist, bins='auto', log=True)\n",
    "# plt.xlim(0,45)\n",
    "# plt.show()\n",
    "\n",
    "# print('Normalized plots')\n",
    "# plt.figure(figsize=(12,6))\n",
    "# plt.subplot(211)\n",
    "# plt.hist(data.duration/MAX_DURATION, bins='auto', log=True)\n",
    "# plt.xlim(0,1)\n",
    "# plt.subplot(212)\n",
    "# plt.hist(data.trip_dist/MAX_DISTANCE, bins='auto', log=True)\n",
    "# plt.xlim(0,1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAX_DURATION = 7200\n",
    "MAX_DISTANCE = 40\n",
    "\n",
    "data['trip_dist_norm'] = data.trip_dist/MAX_DISTANCE\n",
    "data['duration_norm'] = data.duration/MAX_DURATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for training   = 6806066\n",
      "Number of samples for validation = 1944590\n",
      "Number of samples for testing    = 972296\n"
     ]
    }
   ],
   "source": [
    "# Encoding time with sin/cos\n",
    "data['avg_hour_sin'] = np.sin(data.avg_hour * 2 * np.pi/ 24)\n",
    "data['avg_hour_cos'] = np.cos(data.avg_hour * 2 * np.pi/ 24)\n",
    "data['week_day_sin'] = np.sin(data.week_day * 2 * np.pi/ 24)\n",
    "data['week_day_cos'] = np.cos(data.week_day * 2 * np.pi/ 24)\n",
    "\n",
    "# Encoding time categorically\n",
    "# data[['avg_hour_cat_' + str(i) for i in range(24)]] = pd.DataFrame(to_categorical(data.avg_hour)).astype('int')\n",
    "# data[['week_day_cat_' + str(i) for i in  range(7)]] = pd.DataFrame(to_categorical(data.week_day)).astype('int')\n",
    "\n",
    "# Defining features accordingly\n",
    "FEATS = ['pu_lon_n', 'pu_lat_n', 'do_lon_n', 'do_lat_n', 'vec_dist']\n",
    "[FEATS.append(i) for i in ['avg_hour_sin', 'avg_hour_cos', 'week_day_sin', 'week_day_cos']]    #Sine/cosine\n",
    "#[FEATS.append('week_day_cat_' + str(i)) for i in  range(7)];                                   #Categorical (weekday)\n",
    "#[FEATS.append('avg_hour_cat_' + str(i)) for i in range(24)];                                   #Categorical (avghour)\n",
    "\n",
    "TARGET = ['duration_norm', 'trip_dist_norm'] # 2 tasks (normalized)\n",
    "N_FEATS = len(FEATS)\n",
    "\n",
    "train_data = data.iloc[train_samples_ids]\n",
    "valid_data = data.iloc[valid_samples_ids]\n",
    "test_data  = data.iloc[test_samples_ids]\n",
    "\n",
    "print('Number of samples for training   =', len(train_data))\n",
    "print('Number of samples for validation =', len(valid_data))\n",
    "print('Number of samples for testing    =', len(test_data))\n",
    "\n",
    "train_input, train_output = np.array(train_data[FEATS]), np.array(train_data[TARGET])\n",
    "valid_input, valid_output = np.array(valid_data[FEATS]), np.array(valid_data[TARGET])\n",
    "test_input,  test_output  = np.array( test_data[FEATS]), np.array( test_data[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>pu_t</th>\n",
       "      <th>do_t</th>\n",
       "      <th>trip_dist</th>\n",
       "      <th>pu_lon</th>\n",
       "      <th>pu_lat</th>\n",
       "      <th>do_lon</th>\n",
       "      <th>do_lat</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>...</th>\n",
       "      <th>pu_lon_n_q</th>\n",
       "      <th>pu_lat_n_q</th>\n",
       "      <th>do_lon_n_q</th>\n",
       "      <th>do_lat_n_q</th>\n",
       "      <th>trip_dist_norm</th>\n",
       "      <th>duration_norm</th>\n",
       "      <th>avg_hour_sin</th>\n",
       "      <th>avg_hour_cos</th>\n",
       "      <th>week_day_sin</th>\n",
       "      <th>week_day_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-16 15:32:19</td>\n",
       "      <td>2016-04-16 15:48:38</td>\n",
       "      <td>1.66</td>\n",
       "      <td>-73.989342</td>\n",
       "      <td>40.734261</td>\n",
       "      <td>-73.973190</td>\n",
       "      <td>40.749870</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>965.0</td>\n",
       "      <td>1131.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1187.0</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.135972</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-23 22:55:51</td>\n",
       "      <td>2016-04-23 23:04:15</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-73.967606</td>\n",
       "      <td>40.762981</td>\n",
       "      <td>-73.939804</td>\n",
       "      <td>40.798103</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-04-03 01:18:07</td>\n",
       "      <td>2016-04-03 01:29:10</td>\n",
       "      <td>4.24</td>\n",
       "      <td>-73.968681</td>\n",
       "      <td>40.754639</td>\n",
       "      <td>-73.994118</td>\n",
       "      <td>40.709721</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.092083</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-04-27 15:16:36</td>\n",
       "      <td>2016-04-27 15:19:59</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-73.963608</td>\n",
       "      <td>40.777000</td>\n",
       "      <td>-73.972328</td>\n",
       "      <td>40.782280</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.028194</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-04-26 07:33:33</td>\n",
       "      <td>2016-04-26 07:57:27</td>\n",
       "      <td>5.90</td>\n",
       "      <td>-73.965652</td>\n",
       "      <td>40.754841</td>\n",
       "      <td>-73.990768</td>\n",
       "      <td>40.745171</td>\n",
       "      <td>21.5</td>\n",
       "      <td>4.46</td>\n",
       "      <td>...</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>0.1475</td>\n",
       "      <td>0.199167</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>9.659258e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_index                pu_t                do_t  trip_dist  \\\n",
       "0               0 2016-04-16 15:32:19 2016-04-16 15:48:38       1.66   \n",
       "1               1 2016-04-23 22:55:51 2016-04-23 23:04:15       3.00   \n",
       "2               2 2016-04-03 01:18:07 2016-04-03 01:29:10       4.24   \n",
       "3               3 2016-04-27 15:16:36 2016-04-27 15:19:59       0.64   \n",
       "4               4 2016-04-26 07:33:33 2016-04-26 07:57:27       5.90   \n",
       "\n",
       "      pu_lon     pu_lat     do_lon     do_lat  fare_amount  tip_amount  ...  \\\n",
       "0 -73.989342  40.734261 -73.973190  40.749870         11.5        1.00  ...   \n",
       "1 -73.967606  40.762981 -73.939804  40.798103         10.5        0.00  ...   \n",
       "2 -73.968681  40.754639 -73.994118  40.709721         13.5        0.00  ...   \n",
       "3 -73.963608  40.777000 -73.972328  40.782280          4.5        0.00  ...   \n",
       "4 -73.965652  40.754841 -73.990768  40.745171         21.5        4.46  ...   \n",
       "\n",
       "   pu_lon_n_q  pu_lat_n_q  do_lon_n_q  do_lat_n_q  trip_dist_norm  \\\n",
       "0       965.0      1131.0      1023.0      1187.0          0.0415   \n",
       "1      1043.0      1234.0      1142.0      1360.0          0.0750   \n",
       "2      1039.0      1204.0       948.0      1043.0          0.1060   \n",
       "3      1057.0      1284.0      1026.0      1303.0          0.0160   \n",
       "4      1050.0      1205.0       960.0      1170.0          0.1475   \n",
       "\n",
       "   duration_norm  avg_hour_sin  avg_hour_cos  week_day_sin  week_day_cos  \n",
       "0       0.135972     -0.707107     -0.707107      0.965926  2.588190e-01  \n",
       "1       0.070000     -0.258819      0.965926      0.965926  2.588190e-01  \n",
       "2       0.092083      0.258819      0.965926      1.000000  6.123234e-17  \n",
       "3       0.028194     -0.707107     -0.707107      0.500000  8.660254e-01  \n",
       "4       0.199167      0.965926     -0.258819      0.258819  9.659258e-01  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_func(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true-y_pred))\n",
    "def mape_func(y_true, y_pred):\n",
    "    return 100*np.mean(np.abs((y_true-y_pred)/y_true))\n",
    "def mare_func(y_true, y_pred):\n",
    "    return 100*np.sum(np.abs(y_true-y_pred))/np.sum(np.abs(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE  = 0.03888184363905187\n",
      "MAPE = 50.05643085480839\n",
      "MARE = 32.066189931672724\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg.fit(np.vstack((train_input,  valid_input)),\n",
    "            np.vstack((train_output,valid_output))[:,0:1])\n",
    "\n",
    "lin_reg_pred = lin_reg.predict(test_input)\n",
    "\n",
    "print('MAE  =',mae_func(test_output[:,0:1], lin_reg_pred))\n",
    "print('MAPE =',mape_func(test_output[:,0:1], lin_reg_pred))\n",
    "print('MARE =',mare_func(test_output[:,0:1], lin_reg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE  = 0.0385784803344784\n",
      "MAPE = 49.80183056579425\n",
      "MARE = 31.81600361249874\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg.fit(np.vstack((train_input,  valid_input)),\n",
    "            np.vstack((train_output,valid_output))[:,0:1])\n",
    "\n",
    "lin_reg_pred = lin_reg.predict(test_input)\n",
    "\n",
    "print('MAE  =',mae_func(test_output[:,0:1], lin_reg_pred))\n",
    "print('MAPE =',mape_func(test_output[:,0:1], lin_reg_pred))\n",
    "print('MARE =',mare_func(test_output[:,0:1], lin_reg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load chunks for each partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_p = 0.7\n",
    "# valid_p = 0.2\n",
    "\n",
    "# train_chunks_ids, valid_chunks_ids, test_chunks_ids = np.split(np.random.permutation(file_indices),\n",
    "#                                                                [int(n_files*(train_p)),\n",
    "#                                                                 int(n_files*(train_p + valid_p))])\n",
    "# print('Number of chunks for training   =', len(train_chunks_ids))\n",
    "# print('Number of chunks for validation =', len(valid_chunks_ids))\n",
    "# print('Number of chunks for testing    =', len(test_chunks_ids))\n",
    "\n",
    "# for chunk_id in train_chunks_ids:\n",
    "#     train_data = train_data.append(pkl.load(open('../data/processed_chunks/processed_ttd_chunk_{}.p'.format(chunk_id), 'rb')))\n",
    "# for chunk_id in valid_chunks_ids:\n",
    "#     valid_data = valid_data.append(pkl.load(open('../data/processed_chunks/processed_ttd_chunk_{}.p'.format(chunk_id), 'rb')))\n",
    "# for chunk_id in test_chunks_ids:\n",
    "#     test_data = test_data.append(pkl.load(open('../data/processed_chunks/processed_ttd_chunk_{}.p'.format(chunk_id), 'rb')))\n",
    "      \n",
    "# print('Number of trips for training =', len(train_data))\n",
    "# print('Number of trips for validation =', len(valid_data))\n",
    "# print('Number of trips for testing =', len(test_data))\n",
    "\n",
    "# FEATS = ['pu_lon_n', 'pu_lat_n', 'do_lon_n', 'do_lat_n', 'vec_dist', 'avg_hour', 'week_day']\n",
    "# TARGET = ['duration']\n",
    "\n",
    "# train_input, train_output = np.array(train_data[FEATS]), np.array(train_data[TARGET])\n",
    "# valid_input, valid_output = np.array(valid_data[FEATS]), np.array(valid_data[TARGET])\n",
    "# test_input,  test_output  = np.array( test_data[FEATS]), np.array( test_data[TARGET])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This generator will:\n",
    "# # 1) Randomly pick a chunk (which has around 100k trips)\n",
    "# # 2) Explore that chunk, until it visits about 50% of it\n",
    "# # 3) Move to another chunk and do the same\n",
    "# #\n",
    "# # Visitation percentage can be increased. There is a chance of returning to that same chunk in the future\n",
    "\n",
    "# def data_generator(chunk_ids, batch_size):\n",
    "    \n",
    "#     # A value of -1 indicates no chunk has been read\n",
    "#     chunk_id = -1\n",
    "#     n_samples_left = 0\n",
    "    \n",
    "#     while True:\n",
    "        \n",
    "#         if chunk_id == -1 or n_samples_left < batch_size:\n",
    "#             # Randomly pick a chunk\n",
    "#             chunk_id = np.random.choice(chunk_ids)            \n",
    "#             chunk = pkl.load(open('../data/processed_chunks/processed_ttd_chunk_{}.p'.format(chunk_id), 'rb'))            \n",
    "#             n_samples_left = len(chunk)\n",
    "        \n",
    "#         # Sample batch\n",
    "#         batch = chunk.sample(n=batch_size)\n",
    "#         batch_input  = batch[['pu_lon_n', 'pu_lat_n', 'do_lon_n', 'do_lat_n', 'vec_dist', 'avg_hour', 'week_day']]\n",
    "#         batch_output = batch[['duration']]\n",
    "        \n",
    "#         # Drop batch from chunk (avoid repeating samples next time)\n",
    "#         chunk.drop(batch.index, inplace=True)\n",
    "        \n",
    "#         n_samples_left = len(chunk)\n",
    "        \n",
    "#         # Return a tuple of (input,output) to feed the network\n",
    "#         batch_x = np.array( batch_input )\n",
    "#         batch_y = np.array( batch_output )\n",
    "        \n",
    "#         # Comment this before using\n",
    "#         yield( batch_x, batch_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"[INFO] training w/ generator...\")\n",
    "\n",
    "# #NUM_TRAIN_IMAGES // BS,\n",
    "# #NUM_TEST_IMAGES // BS,\n",
    "\n",
    "# STEPS_PER_EPOCH_TRAIN = 0.7*650*100000 // BATCH_SIZE\n",
    "# STEPS_PER_EPOCH_VALID = 0.2*650*100000 // BATCH_SIZE\n",
    "\n",
    "# H = model.fit_generator(generator=train_generator,\n",
    "#                         steps_per_epoch=STEPS_PER_EPOCH_TRAIN,\n",
    "#                         epochs=NUM_EPOCHS,\n",
    "#                         validation_data=valid_generator,\n",
    "#                         validation_steps=STEPS_PER_EPOCH_VALID,\n",
    "#                     )\n",
    "\n",
    "# train_generator = data_generator(train_chunks_ids, batch_size=BATCH_SIZE)\n",
    "# valid_generator = data_generator(valid_chunks_ids, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv_model():\n",
    "    \n",
    "    input_layer = Input(shape=(2000,2000,1,))\n",
    " \n",
    "    conv = Conv2D(25, (3,3), padding='valid', activation='relu', name = 'conv1')(input_layer)\n",
    "    conv = Conv2D(25, (3,3), padding='valid', activation='relu', name = 'conv2')(conv)\n",
    "    conv = Conv2D(50, (5,5), padding='valid', activation='relu', name = 'conv3')(conv)\n",
    "    \n",
    "    conv = Conv2D(50, (5,5), padding='valid', activation='relu', name = 'conv4')(conv)\n",
    "    pool = AveragePooling2D(pool_size=(4,4), name = 'pool1')(conv)\n",
    "    \n",
    "    conv = Conv2D(50, (5,5), padding='valid', activation='relu', name = 'conv5')(pool)\n",
    "    pool = AveragePooling2D(pool_size=(4,4), name = 'pool2')(conv)\n",
    "    \n",
    "    conv = Conv2D(50, (5,5), padding='valid', activation='relu', name = 'conv6')(pool)\n",
    "    pool = AveragePooling2D(pool_size=(4,4), name = 'pool3')(conv)\n",
    "    \n",
    "    conv = Conv2D(50, (5,5), padding='valid', activation='relu', name = 'conv7')(pool)\n",
    "    pool = AveragePooling2D(pool_size=(4,4), name = 'pool4')(conv)\n",
    "    \n",
    "    flat = Flatten()(pool)\n",
    "\n",
    "    dense = Dense(100, name = 'dense1', activation  = 'relu')(flat)\n",
    "    dense = Dense( 40, name = 'dense2', activation  = 'relu')(dense)\n",
    "    dense = Dense(  1, name = 'output')(dense)    \n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=dense)\n",
    "\n",
    "    opt = optimizers.Adam(lr=0.001)\n",
    "    \n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=opt,\n",
    "                  metrics=[mape, mae, mare])\n",
    "    return model\n",
    "\n",
    "conv_model = build_conv_model()\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "shared_dense1 (Dense)        (None, 100)               1000      \n",
      "_________________________________________________________________\n",
      "shared_dense2 (Dense)        (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "shared_dense3 (Dense)        (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "shared_dense4 (Dense)        (None, 300)               60300     \n",
      "_________________________________________________________________\n",
      "t1_dense3 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "t1_dense4 (Dense)            (None, 40)                4040      \n",
      "_________________________________________________________________\n",
      "duration (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 125,781\n",
      "Trainable params: 125,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(alpha = 0):\n",
    "    \n",
    "    input_layer = Input(shape=(N_FEATS,))\n",
    "    \n",
    "    hidden_layer = Dense(100, name = 'shared_dense1', activation  = 'relu'))(input_layer)\n",
    "    hidden_layer = Dense(100, name = 'shared_dense2', activation  = 'relu')(hidden_layer)\n",
    "    hidden_layer = Dense(200, name = 'shared_dense3', activation  = 'relu')(hidden_layer)\n",
    "    hidden_layer = Dense(300, name = 'shared_dense4', activation  = 'relu')(hidden_layer)\n",
    "    \n",
    "    # Task 1\n",
    "#    hidden1_layer = Dense(300, name = 't1_dense1', activation  = 'relu')(hidden_layer) # NEW LAYER NEW\n",
    "#    hidden1_layer = Dense(200, name = 't1_dense2', activation  = 'relu')(hidden_layer) # NEW LAYER\n",
    "    hidden1_layer = Dense(100, name = 't1_dense3', activation  = 'relu')(hidden_layer)\n",
    "    hidden1_layer = Dense( 40, name = 't1_dense4', activation  = 'relu')(hidden1_layer)\n",
    "    output1_layer = Dense(  1, name = 'duration')(hidden1_layer)\n",
    "    \n",
    "#    # Task 2\n",
    "#     hidden2_layer = Dense(100, name = 't2_dense1', activation  = 'relu')(hidden_layer)\n",
    "#     hidden2_layer = Dense( 40, name = 't2_dense2', activation  = 'relu')(hidden2_layer)\n",
    "#     output2_layer = Dense(  1, name = 'distance')(hidden2_layer)\n",
    "#\n",
    "#     model = Model(inputs=input_layer, outputs=[output1_layer, output2_layer])\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output1_layer)\n",
    "\n",
    "    opt = optimizers.Adam(lr=0.001)\n",
    "    \n",
    "#     LOSS_WEIGHTS = [1,      # MAIN TASK\n",
    "#                     alpha]  # AUXILIARY TASK\n",
    "\n",
    "#     model.compile(loss=['mse', 'mse'],\n",
    "#                   optimizer=opt,\n",
    "#                   metrics=[mape, mae, mare],\n",
    "#                   loss_weights=LOSS_WEIGHTS)\n",
    "    \n",
    "    model.compile(loss=huber_loss,\n",
    "                  optimizer=opt,\n",
    "                  metrics=[mape, mae, mare])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "base = 5\n",
    "test_pts = [0,\n",
    "            base**-4,\n",
    "            base**-3.5,\n",
    "            base**-3, \n",
    "            base**-2.5, \n",
    "            base**-2, \n",
    "            base**-1.5,\n",
    "            base**-1,\n",
    "            base**-.5,\n",
    "            base**0,\n",
    "            base**0.125,\n",
    "            base**0.250,\n",
    "            base**0.375,\n",
    "            base**0.500]\n",
    "\n",
    "ALPHA_VALUES = test_pts\n",
    "\n",
    "print(len(test_pts))\n",
    "plt.figure(figsize=(10,1))\n",
    "plt.scatter(test_pts, np.zeros(len(test_pts)))\n",
    "plt.ylim((-.1,.1))\n",
    "plt.xlim((1e-3,5))\n",
    "plt.xscale('log')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "NUM_EPOCHS = 75 #100\n",
    "\n",
    "for a in ALPHA_VALUES:\n",
    "    \n",
    "    model = build_model(alpha=a)\n",
    "\n",
    "    #model.metrics_names = [rename_metric_name(x) for x in model.metrics_names]    \n",
    "    \n",
    "    print('Training with alpha =', a)\n",
    "    \n",
    "    time_stamp = time()\n",
    "    print('Time stamp:', time_stamp)\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir='tb_logs_norm_coord_downsamp_balanced/{}'.format(time_stamp))\n",
    "\n",
    "    model.fit(x=train_input,\n",
    "              y=[train_output[:,0], train_output[:,1]],\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=NUM_EPOCHS,\n",
    "              validation_data=(valid_input, [valid_output[:,0], valid_output[:,1]]),\n",
    "              callbacks=[tensorboard])\n",
    "    \n",
    "    # Save model\n",
    "    model_json = model.to_json()\n",
    "    with open(\"../keras_models_norm/model_{}.json\".format(time_stamp), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"../keras_models_norm/model_{}.h5\".format(time_stamp))\n",
    "    print(\"Model saved to disk.\")\n",
    "    \n",
    "    # EVALUATION ON TEST DATA\n",
    "    score = model.evaluate(test_input, [test_output[:,0],test_output[:,1]], batch_size=BATCH_SIZE)\n",
    "\n",
    "    # Two tasks\n",
    "    print('[global_loss, loss, loss_aux_distance] =', end='\\n\\t')\n",
    "    print(score[:3])\n",
    "    print('[mape, mae, mare] =', end='\\n\\t')\n",
    "    print(score[3:6])\n",
    "    print('[mape_aux_distance, mae_aux_distance, mare_aux_distance] =', end='\\n\\t')\n",
    "    print(score[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENAME FOR MULTI-TASK (facilitate visualization on tensorboard)\n",
    "def rename_metric_name(x):\n",
    "    return 'global_loss' if x == 'loss' else x[1+x.find('_'):] + ('_aux_distance' if 'distance' in x else '')\n",
    "model.metrics_names = [rename_metric_name(x) for x in model.metrics_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time stamp: 1554861033.7310662\n",
      "Train on 6806066 samples, validate on 1944590 samples\n",
      "Epoch 1/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 0.0011 - mape: 35.1836 - mae: 0.0312 - mare: 25.7265 - val_loss: 9.8301e-04 - val_mape: 32.3171 - val_mae: 0.0289 - val_mare: 23.7874\n",
      "Epoch 2/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 9.1672e-04 - mape: 30.9196 - mae: 0.0278 - mare: 22.9431 - val_loss: 8.8675e-04 - val_mape: 29.2647 - val_mae: 0.0271 - val_mare: 22.3173\n",
      "Epoch 3/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 8.6769e-04 - mape: 29.5690 - mae: 0.0269 - mare: 22.1392 - val_loss: 8.5130e-04 - val_mape: 29.5695 - val_mae: 0.0266 - val_mare: 21.8806\n",
      "Epoch 4/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 8.4790e-04 - mape: 29.0172 - mae: 0.0265 - mare: 21.8090 - val_loss: 8.4218e-04 - val_mape: 29.9654 - val_mae: 0.0264 - val_mare: 21.7826\n",
      "Epoch 5/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 8.3584e-04 - mape: 28.6853 - mae: 0.0262 - mare: 21.6140 - val_loss: 8.3534e-04 - val_mape: 30.4767 - val_mae: 0.0268 - val_mare: 22.0860\n",
      "Epoch 6/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 8.2690e-04 - mape: 28.4345 - mae: 0.0260 - mare: 21.4597 - val_loss: 8.2778e-04 - val_mape: 28.3220 - val_mae: 0.0259 - val_mare: 21.3168\n",
      "Epoch 7/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 8.2040e-04 - mape: 28.2263 - mae: 0.0259 - mare: 21.3496 - val_loss: 8.0959e-04 - val_mape: 28.5826 - val_mae: 0.0260 - val_mare: 21.4366\n",
      "Epoch 8/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 8.1504e-04 - mape: 28.0604 - mae: 0.0258 - mare: 21.2594 - val_loss: 8.0616e-04 - val_mape: 27.9657 - val_mae: 0.0257 - val_mare: 21.2043\n",
      "Epoch 9/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 8.1054e-04 - mape: 27.9134 - mae: 0.0257 - mare: 21.1797 - val_loss: 8.2145e-04 - val_mape: 29.5662 - val_mae: 0.0265 - val_mare: 21.8224\n",
      "Epoch 10/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 8.0683e-04 - mape: 27.8157 - mae: 0.0256 - mare: 21.1193 - val_loss: 7.9365e-04 - val_mape: 27.5249 - val_mae: 0.0253 - val_mare: 20.8445\n",
      "Epoch 11/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 8.0409e-04 - mape: 27.7463 - mae: 0.0256 - mare: 21.0771 - val_loss: 8.0402e-04 - val_mape: 27.8461 - val_mae: 0.0256 - val_mare: 21.0544\n",
      "Epoch 12/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 8.0046e-04 - mape: 27.6438 - mae: 0.0255 - mare: 21.0150 - val_loss: 7.9876e-04 - val_mape: 28.6177 - val_mae: 0.0255 - val_mare: 21.0339\n",
      "Epoch 13/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.9746e-04 - mape: 27.5292 - mae: 0.0254 - mare: 20.9649 - val_loss: 8.0378e-04 - val_mape: 28.4418 - val_mae: 0.0258 - val_mare: 21.2594\n",
      "Epoch 14/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.9568e-04 - mape: 27.4867 - mae: 0.0254 - mare: 20.9354 - val_loss: 7.9644e-04 - val_mape: 27.5214 - val_mae: 0.0253 - val_mare: 20.8487\n",
      "Epoch 15/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.9318e-04 - mape: 27.4032 - mae: 0.0253 - mare: 20.8916 - val_loss: 8.0518e-04 - val_mape: 27.2790 - val_mae: 0.0254 - val_mare: 20.9373\n",
      "Epoch 16/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.9116e-04 - mape: 27.3481 - mae: 0.0253 - mare: 20.8595 - val_loss: 7.9104e-04 - val_mape: 25.8420 - val_mae: 0.0251 - val_mare: 20.6816\n",
      "Epoch 17/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.8993e-04 - mape: 27.3343 - mae: 0.0253 - mare: 20.8415 - val_loss: 8.2057e-04 - val_mape: 26.5679 - val_mae: 0.0256 - val_mare: 21.0655\n",
      "Epoch 18/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.8813e-04 - mape: 27.2711 - mae: 0.0252 - mare: 20.8099 - val_loss: 7.9025e-04 - val_mape: 28.3005 - val_mae: 0.0255 - val_mare: 21.0031\n",
      "Epoch 19/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.8606e-04 - mape: 27.1928 - mae: 0.0252 - mare: 20.7751 - val_loss: 7.8813e-04 - val_mape: 25.7869 - val_mae: 0.0248 - val_mare: 20.4504\n",
      "Epoch 20/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.8496e-04 - mape: 27.1541 - mae: 0.0252 - mare: 20.7551 - val_loss: 7.9040e-04 - val_mape: 27.3617 - val_mae: 0.0251 - val_mare: 20.7156\n",
      "Epoch 21/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.8403e-04 - mape: 27.1359 - mae: 0.0252 - mare: 20.7401 - val_loss: 7.8257e-04 - val_mape: 27.1244 - val_mae: 0.0251 - val_mare: 20.6900\n",
      "Epoch 22/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.8213e-04 - mape: 27.0860 - mae: 0.0251 - mare: 20.7115 - val_loss: 7.8877e-04 - val_mape: 29.1248 - val_mae: 0.0258 - val_mare: 21.2815\n",
      "Epoch 23/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.8109e-04 - mape: 27.0422 - mae: 0.0251 - mare: 20.6956 - val_loss: 7.8164e-04 - val_mape: 29.1755 - val_mae: 0.0255 - val_mare: 21.0516\n",
      "Epoch 24/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.8026e-04 - mape: 27.0215 - mae: 0.0251 - mare: 20.6804 - val_loss: 7.8287e-04 - val_mape: 28.0981 - val_mae: 0.0253 - val_mare: 20.8780\n",
      "Epoch 25/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.7941e-04 - mape: 26.9842 - mae: 0.0251 - mare: 20.6599 - val_loss: 7.8890e-04 - val_mape: 27.7902 - val_mae: 0.0257 - val_mare: 21.1538\n",
      "Epoch 26/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.7758e-04 - mape: 26.9307 - mae: 0.0250 - mare: 20.6339 - val_loss: 7.7794e-04 - val_mape: 26.6320 - val_mae: 0.0251 - val_mare: 20.7141\n",
      "Epoch 27/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.7702e-04 - mape: 26.9133 - mae: 0.0250 - mare: 20.6234 - val_loss: 7.7847e-04 - val_mape: 25.9596 - val_mae: 0.0247 - val_mare: 20.3483\n",
      "Epoch 28/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.7636e-04 - mape: 26.8951 - mae: 0.0250 - mare: 20.6122 - val_loss: 7.8225e-04 - val_mape: 26.2791 - val_mae: 0.0248 - val_mare: 20.3943\n",
      "Epoch 29/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.7485e-04 - mape: 26.8509 - mae: 0.0250 - mare: 20.5864 - val_loss: 7.7947e-04 - val_mape: 27.5892 - val_mae: 0.0251 - val_mare: 20.6956\n",
      "Epoch 30/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.7414e-04 - mape: 26.8330 - mae: 0.0250 - mare: 20.5728 - val_loss: 7.8643e-04 - val_mape: 27.9515 - val_mae: 0.0253 - val_mare: 20.8480\n",
      "Epoch 31/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.7396e-04 - mape: 26.8368 - mae: 0.0250 - mare: 20.5690 - val_loss: 7.7224e-04 - val_mape: 25.7983 - val_mae: 0.0248 - val_mare: 20.4527\n",
      "Epoch 32/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.7293e-04 - mape: 26.7808 - mae: 0.0249 - mare: 20.5570 - val_loss: 7.7718e-04 - val_mape: 26.8650 - val_mae: 0.0252 - val_mare: 20.7418\n",
      "Epoch 33/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.7165e-04 - mape: 26.7509 - mae: 0.0249 - mare: 20.5372 - val_loss: 7.8494e-04 - val_mape: 29.8757 - val_mae: 0.0258 - val_mare: 21.2565\n",
      "Epoch 34/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.7134e-04 - mape: 26.7335 - mae: 0.0249 - mare: 20.5268 - val_loss: 7.7451e-04 - val_mape: 25.7144 - val_mae: 0.0249 - val_mare: 20.4943\n",
      "Epoch 35/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.7014e-04 - mape: 26.6909 - mae: 0.0249 - mare: 20.5059 - val_loss: 7.7384e-04 - val_mape: 25.4228 - val_mae: 0.0247 - val_mare: 20.3739\n",
      "Epoch 36/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.6999e-04 - mape: 26.6783 - mae: 0.0249 - mare: 20.4988 - val_loss: 7.7639e-04 - val_mape: 26.5168 - val_mae: 0.0246 - val_mare: 20.2991\n",
      "Epoch 37/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.6928e-04 - mape: 26.6656 - mae: 0.0249 - mare: 20.4915 - val_loss: 7.7979e-04 - val_mape: 26.3387 - val_mae: 0.0252 - val_mare: 20.7526\n",
      "Epoch 38/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.6867e-04 - mape: 26.6425 - mae: 0.0248 - mare: 20.4792 - val_loss: 7.6656e-04 - val_mape: 26.8942 - val_mae: 0.0250 - val_mare: 20.6040\n",
      "Epoch 39/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.6746e-04 - mape: 26.6040 - mae: 0.0248 - mare: 20.4595 - val_loss: 7.7051e-04 - val_mape: 24.9528 - val_mae: 0.0245 - val_mare: 20.1774\n",
      "Epoch 40/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.6707e-04 - mape: 26.6054 - mae: 0.0248 - mare: 20.4504 - val_loss: 7.8805e-04 - val_mape: 26.2833 - val_mae: 0.0248 - val_mare: 20.4703\n",
      "Epoch 41/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.6641e-04 - mape: 26.5769 - mae: 0.0248 - mare: 20.4437 - val_loss: 7.7314e-04 - val_mape: 28.0624 - val_mae: 0.0251 - val_mare: 20.6610\n",
      "Epoch 42/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.6627e-04 - mape: 26.5675 - mae: 0.0248 - mare: 20.4413 - val_loss: 7.7416e-04 - val_mape: 26.1741 - val_mae: 0.0246 - val_mare: 20.2527\n",
      "Epoch 43/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.6502e-04 - mape: 26.5320 - mae: 0.0248 - mare: 20.4189 - val_loss: 7.7280e-04 - val_mape: 27.3682 - val_mae: 0.0250 - val_mare: 20.6086\n",
      "Epoch 44/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.6492e-04 - mape: 26.5279 - mae: 0.0248 - mare: 20.4145 - val_loss: 7.8806e-04 - val_mape: 25.1260 - val_mae: 0.0248 - val_mare: 20.4450\n",
      "Epoch 45/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.6388e-04 - mape: 26.4963 - mae: 0.0247 - mare: 20.3987 - val_loss: 7.7559e-04 - val_mape: 27.2346 - val_mae: 0.0251 - val_mare: 20.6764\n",
      "Epoch 46/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.6360e-04 - mape: 26.4921 - mae: 0.0247 - mare: 20.3974 - val_loss: 7.6654e-04 - val_mape: 25.7976 - val_mae: 0.0245 - val_mare: 20.1710\n",
      "Epoch 47/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.6321e-04 - mape: 26.4820 - mae: 0.0247 - mare: 20.3898 - val_loss: 7.7107e-04 - val_mape: 27.1639 - val_mae: 0.0251 - val_mare: 20.6610\n",
      "Epoch 48/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.6247e-04 - mape: 26.4332 - mae: 0.0247 - mare: 20.3737 - val_loss: 7.7250e-04 - val_mape: 25.6854 - val_mae: 0.0246 - val_mare: 20.2379\n",
      "Epoch 49/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.6197e-04 - mape: 26.4403 - mae: 0.0247 - mare: 20.3677 - val_loss: 7.7134e-04 - val_mape: 27.7135 - val_mae: 0.0251 - val_mare: 20.6734\n",
      "Epoch 50/100\n",
      "6806066/6806066 [==============================] - 30s 4us/step - loss: 7.6174e-04 - mape: 26.4332 - mae: 0.0247 - mare: 20.3631 - val_loss: 7.6630e-04 - val_mape: 26.9176 - val_mae: 0.0248 - val_mare: 20.4386\n",
      "Epoch 51/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.6139e-04 - mape: 26.4120 - mae: 0.0247 - mare: 20.3598 - val_loss: 7.6616e-04 - val_mape: 27.7885 - val_mae: 0.0251 - val_mare: 20.6614\n",
      "Epoch 52/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.6078e-04 - mape: 26.4207 - mae: 0.0247 - mare: 20.3526 - val_loss: 7.7189e-04 - val_mape: 28.4390 - val_mae: 0.0254 - val_mare: 20.9444\n",
      "Epoch 53/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.6064e-04 - mape: 26.4025 - mae: 0.0247 - mare: 20.3460 - val_loss: 7.7124e-04 - val_mape: 28.1420 - val_mae: 0.0252 - val_mare: 20.8035\n",
      "Epoch 54/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.5991e-04 - mape: 26.3780 - mae: 0.0247 - mare: 20.3346 - val_loss: 7.6814e-04 - val_mape: 25.5834 - val_mae: 0.0249 - val_mare: 20.5194\n",
      "Epoch 55/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.5977e-04 - mape: 26.3880 - mae: 0.0247 - mare: 20.3349 - val_loss: 7.8960e-04 - val_mape: 25.2674 - val_mae: 0.0248 - val_mare: 20.3938\n",
      "Epoch 56/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.5969e-04 - mape: 26.3524 - mae: 0.0247 - mare: 20.3307 - val_loss: 7.8064e-04 - val_mape: 28.9687 - val_mae: 0.0257 - val_mare: 21.1811\n",
      "Epoch 57/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.5922e-04 - mape: 26.3694 - mae: 0.0247 - mare: 20.3254 - val_loss: 7.6763e-04 - val_mape: 25.3401 - val_mae: 0.0245 - val_mare: 20.1473\n",
      "Epoch 58/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.5868e-04 - mape: 26.3453 - mae: 0.0246 - mare: 20.3134 - val_loss: 7.6691e-04 - val_mape: 25.2957 - val_mae: 0.0244 - val_mare: 20.1447\n",
      "Epoch 59/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.5792e-04 - mape: 26.3139 - mae: 0.0246 - mare: 20.3016 - val_loss: 7.6676e-04 - val_mape: 28.2015 - val_mae: 0.0252 - val_mare: 20.7700\n",
      "Epoch 60/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.5742e-04 - mape: 26.2930 - mae: 0.0246 - mare: 20.2928 - val_loss: 7.7575e-04 - val_mape: 28.5995 - val_mae: 0.0252 - val_mare: 20.7672\n",
      "Epoch 61/100\n",
      "6806066/6806066 [==============================] - 30s 4us/step - loss: 7.5782e-04 - mape: 26.3158 - mae: 0.0246 - mare: 20.3029 - val_loss: 7.7183e-04 - val_mape: 28.4106 - val_mae: 0.0254 - val_mare: 20.9233\n",
      "Epoch 62/100\n",
      "6806066/6806066 [==============================] - 34s 5us/step - loss: 7.5737e-04 - mape: 26.3022 - mae: 0.0246 - mare: 20.2962 - val_loss: 7.6736e-04 - val_mape: 27.3156 - val_mae: 0.0252 - val_mare: 20.7304\n",
      "Epoch 63/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.5660e-04 - mape: 26.2785 - mae: 0.0246 - mare: 20.2841 - val_loss: 7.7458e-04 - val_mape: 25.1655 - val_mae: 0.0245 - val_mare: 20.2097\n",
      "Epoch 64/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.5634e-04 - mape: 26.2691 - mae: 0.0246 - mare: 20.2763 - val_loss: 7.6524e-04 - val_mape: 26.0534 - val_mae: 0.0249 - val_mare: 20.4927\n",
      "Epoch 65/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.5582e-04 - mape: 26.2521 - mae: 0.0246 - mare: 20.2669 - val_loss: 7.5947e-04 - val_mape: 25.7300 - val_mae: 0.0245 - val_mare: 20.1868\n",
      "Epoch 66/100\n",
      "6806066/6806066 [==============================] - 31s 5us/step - loss: 7.5557e-04 - mape: 26.2497 - mae: 0.0246 - mare: 20.2648 - val_loss: 7.6904e-04 - val_mape: 24.9881 - val_mae: 0.0245 - val_mare: 20.1979\n",
      "Epoch 67/100\n",
      "6806066/6806066 [==============================] - 29s 4us/step - loss: 7.5560e-04 - mape: 26.2599 - mae: 0.0246 - mare: 20.2696 - val_loss: 7.7193e-04 - val_mape: 25.4967 - val_mae: 0.0245 - val_mare: 20.1602\n",
      "Epoch 68/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.5550e-04 - mape: 26.2544 - mae: 0.0246 - mare: 20.2670 - val_loss: 7.6103e-04 - val_mape: 25.8272 - val_mae: 0.0245 - val_mare: 20.1873\n",
      "Epoch 69/100\n",
      "6806066/6806066 [==============================] - 30s 4us/step - loss: 7.5518e-04 - mape: 26.2545 - mae: 0.0246 - mare: 20.2630 - val_loss: 7.6863e-04 - val_mape: 25.6177 - val_mae: 0.0247 - val_mare: 20.3274\n",
      "Epoch 70/100\n",
      "6806066/6806066 [==============================] - 31s 4us/step - loss: 7.5497e-04 - mape: 26.2482 - mae: 0.0246 - mare: 20.2575 - val_loss: 7.6782e-04 - val_mape: 26.1240 - val_mae: 0.0246 - val_mare: 20.2767\n",
      "Epoch 71/100\n",
      "6806066/6806066 [==============================] - 31s 5us/step - loss: 7.5467e-04 - mape: 26.2222 - mae: 0.0246 - mare: 20.2512 - val_loss: 7.7268e-04 - val_mape: 25.5810 - val_mae: 0.0248 - val_mare: 20.4123\n",
      "Epoch 72/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.5394e-04 - mape: 26.2123 - mae: 0.0246 - mare: 20.2406 - val_loss: 7.6885e-04 - val_mape: 26.3672 - val_mae: 0.0248 - val_mare: 20.4765\n",
      "Epoch 73/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.5358e-04 - mape: 26.1868 - mae: 0.0245 - mare: 20.2335 - val_loss: 7.6602e-04 - val_mape: 26.7101 - val_mae: 0.0249 - val_mare: 20.5137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "6806066/6806066 [==============================] - 31s 5us/step - loss: 7.5316e-04 - mape: 26.1885 - mae: 0.0245 - mare: 20.2322 - val_loss: 7.6998e-04 - val_mape: 25.2357 - val_mae: 0.0243 - val_mare: 20.0381\n",
      "Epoch 75/100\n",
      "6806066/6806066 [==============================] - 31s 5us/step - loss: 7.5314e-04 - mape: 26.1842 - mae: 0.0245 - mare: 20.2291 - val_loss: 7.7509e-04 - val_mape: 28.6754 - val_mae: 0.0257 - val_mare: 21.1529\n",
      "Epoch 76/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.5326e-04 - mape: 26.1774 - mae: 0.0245 - mare: 20.2318 - val_loss: 7.6885e-04 - val_mape: 27.0286 - val_mae: 0.0248 - val_mare: 20.4511\n",
      "Epoch 77/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.5229e-04 - mape: 26.1544 - mae: 0.0245 - mare: 20.2152 - val_loss: 7.6419e-04 - val_mape: 27.5290 - val_mae: 0.0251 - val_mare: 20.6936\n",
      "Epoch 78/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.5244e-04 - mape: 26.1758 - mae: 0.0245 - mare: 20.2201 - val_loss: 7.6920e-04 - val_mape: 25.8259 - val_mae: 0.0248 - val_mare: 20.4741\n",
      "Epoch 79/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.5245e-04 - mape: 26.1676 - mae: 0.0245 - mare: 20.2170 - val_loss: 7.6418e-04 - val_mape: 26.1652 - val_mae: 0.0246 - val_mare: 20.2422\n",
      "Epoch 80/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.5182e-04 - mape: 26.1358 - mae: 0.0245 - mare: 20.2082 - val_loss: 7.8233e-04 - val_mape: 26.0271 - val_mae: 0.0245 - val_mare: 20.1969\n",
      "Epoch 81/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.5194e-04 - mape: 26.1573 - mae: 0.0245 - mare: 20.2147 - val_loss: 7.7602e-04 - val_mape: 27.8595 - val_mae: 0.0255 - val_mare: 20.9801\n",
      "Epoch 82/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.5145e-04 - mape: 26.1190 - mae: 0.0245 - mare: 20.1988 - val_loss: 7.7430e-04 - val_mape: 25.4570 - val_mae: 0.0246 - val_mare: 20.2429\n",
      "Epoch 83/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.5120e-04 - mape: 26.1133 - mae: 0.0245 - mare: 20.1980 - val_loss: 7.6963e-04 - val_mape: 26.1974 - val_mae: 0.0244 - val_mare: 20.0882\n",
      "Epoch 84/100\n",
      "6806066/6806066 [==============================] - 31s 5us/step - loss: 7.5058e-04 - mape: 26.1045 - mae: 0.0245 - mare: 20.1905 - val_loss: 7.5894e-04 - val_mape: 26.6017 - val_mae: 0.0245 - val_mare: 20.1950\n",
      "Epoch 85/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.5038e-04 - mape: 26.0885 - mae: 0.0245 - mare: 20.1828 - val_loss: 7.5813e-04 - val_mape: 25.8911 - val_mae: 0.0243 - val_mare: 20.0287\n",
      "Epoch 86/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.5071e-04 - mape: 26.1077 - mae: 0.0245 - mare: 20.1913 - val_loss: 7.6478e-04 - val_mape: 24.1263 - val_mae: 0.0241 - val_mare: 19.8874\n",
      "Epoch 87/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.5046e-04 - mape: 26.1104 - mae: 0.0245 - mare: 20.1895 - val_loss: 7.8030e-04 - val_mape: 27.4372 - val_mae: 0.0248 - val_mare: 20.4576\n",
      "Epoch 88/100\n",
      "6806066/6806066 [==============================] - 30s 4us/step - loss: 7.5000e-04 - mape: 26.1030 - mae: 0.0245 - mare: 20.1852 - val_loss: 7.5806e-04 - val_mape: 25.8482 - val_mae: 0.0245 - val_mare: 20.2214\n",
      "Epoch 89/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.4943e-04 - mape: 26.0593 - mae: 0.0245 - mare: 20.1704 - val_loss: 7.6503e-04 - val_mape: 26.0038 - val_mae: 0.0247 - val_mare: 20.3592\n",
      "Epoch 90/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.4992e-04 - mape: 26.0814 - mae: 0.0245 - mare: 20.1798 - val_loss: 7.5895e-04 - val_mape: 25.3499 - val_mae: 0.0244 - val_mare: 20.1238\n",
      "Epoch 91/100\n",
      "6806066/6806066 [==============================] - 31s 5us/step - loss: 7.4873e-04 - mape: 26.0734 - mae: 0.0245 - mare: 20.1671 - val_loss: 7.6097e-04 - val_mape: 25.2608 - val_mae: 0.0243 - val_mare: 19.9832\n",
      "Epoch 92/100\n",
      "6806066/6806066 [==============================] - 29s 4us/step - loss: 7.4908e-04 - mape: 26.0553 - mae: 0.0245 - mare: 20.1707 - val_loss: 7.6522e-04 - val_mape: 25.2174 - val_mae: 0.0245 - val_mare: 20.1545\n",
      "Epoch 93/100\n",
      "6806066/6806066 [==============================] - 31s 5us/step - loss: 7.4911e-04 - mape: 26.0625 - mae: 0.0245 - mare: 20.1660 - val_loss: 7.7227e-04 - val_mape: 25.3942 - val_mae: 0.0248 - val_mare: 20.4567\n",
      "Epoch 94/100\n",
      "6806066/6806066 [==============================] - 31s 5us/step - loss: 7.4824e-04 - mape: 26.0380 - mae: 0.0245 - mare: 20.1540 - val_loss: 7.6915e-04 - val_mape: 25.2731 - val_mae: 0.0242 - val_mare: 19.9638\n",
      "Epoch 95/100\n",
      "6806066/6806066 [==============================] - 31s 5us/step - loss: 7.4828e-04 - mape: 26.0248 - mae: 0.0245 - mare: 20.1538 - val_loss: 7.6008e-04 - val_mape: 26.8064 - val_mae: 0.0246 - val_mare: 20.2713\n",
      "Epoch 96/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.4800e-04 - mape: 26.0081 - mae: 0.0244 - mare: 20.1476 - val_loss: 7.5824e-04 - val_mape: 25.1313 - val_mae: 0.0244 - val_mare: 20.0697\n",
      "Epoch 97/100\n",
      "6806066/6806066 [==============================] - 33s 5us/step - loss: 7.4749e-04 - mape: 26.0241 - mae: 0.0244 - mare: 20.1424 - val_loss: 7.6044e-04 - val_mape: 25.4107 - val_mae: 0.0246 - val_mare: 20.2928\n",
      "Epoch 98/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.4784e-04 - mape: 26.0407 - mae: 0.0244 - mare: 20.1523 - val_loss: 7.5988e-04 - val_mape: 26.0188 - val_mae: 0.0243 - val_mare: 20.0459\n",
      "Epoch 99/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.4741e-04 - mape: 26.0166 - mae: 0.0244 - mare: 20.1419 - val_loss: 7.8205e-04 - val_mape: 28.3491 - val_mae: 0.0257 - val_mare: 21.1500\n",
      "Epoch 100/100\n",
      "6806066/6806066 [==============================] - 32s 5us/step - loss: 7.4784e-04 - mape: 26.0209 - mae: 0.0244 - mare: 20.1494 - val_loss: 7.7721e-04 - val_mape: 26.3409 - val_mae: 0.0250 - val_mare: 20.5784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2095f855da0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "time_stamp = time()\n",
    "print('Time stamp:', time_stamp)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='tb_logs/{}'.format(time_stamp))\n",
    "\n",
    "# model.fit(x=train_input,\n",
    "#           y=[train_output[:,0], train_output[:,1]],\n",
    "#           batch_size=BATCH_SIZE,\n",
    "#           epochs=NUM_EPOCHS,\n",
    "#           validation_data=(valid_input, [valid_output[:,0], valid_output[:,1]]),\n",
    "#           callbacks=[tensorboard])\n",
    "\n",
    "model.fit(x=train_input,\n",
    "          y=train_output[:,0],\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          validation_data=(valid_input,valid_output[:,0]),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_json = model.to_json()\n",
    "with open(\"../keras_models/model_{}.json\".format(time_stamp), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"../keras_models/model_{}.h5\".format(time_stamp))\n",
    "print(\"Model saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION ON TEST DATA\n",
    "#score = model.evaluate(test_input, test_output[:,0], batch_size=BATCH_SIZE)\n",
    "\n",
    "score = model.evaluate(test_input, [test_output[:,0],test_output[:,1]], batch_size=BATCH_SIZE)\n",
    "\n",
    "# Single task\n",
    "#print('[LOSS, MAPE, MAE, MARE] =', score)\n",
    "\n",
    "# Two tasks\n",
    "print('[global_loss, loss, loss_aux_distance] =', end='\\n\\t')\n",
    "print(score[:3])\n",
    "print('[mape, mae, mare] =', end='\\n\\t')\n",
    "print(score[3:6])\n",
    "print('[mape_aux_distance, mae_aux_distance, mare_aux_distance] =', end='\\n\\t')\n",
    "print(score[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(test_input, open('test_input.dat', 'wb'))\n",
    "pkl.dump(test_output, open('test_output.dat', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISTANCE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "shared_dense1 (Dense)        (None, 20)                100       \n",
      "_________________________________________________________________\n",
      "shared_dense2 (Dense)        (None, 100)               2100      \n",
      "_________________________________________________________________\n",
      "shared_dense3 (Dense)        (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "distance (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 4,241\n",
      "Trainable params: 4,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Time stamp: 1554907706.8622103\n",
      "Train on 6806066 samples, validate on 1944590 samples\n",
      "Epoch 1/100\n",
      "6806066/6806066 [==============================] - 23s 3us/step - loss: 2.4429e-04 - mape: 26.8326 - mae: 0.0113 - mare: 14.9595 - val_loss: 1.5451e-04 - val_mape: 16.5582 - val_mae: 0.0085 - val_mare: 11.2720\n",
      "Epoch 2/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.5914e-04 - mape: 18.8992 - mae: 0.0092 - mare: 12.1664 - val_loss: 1.5326e-04 - val_mape: 16.1371 - val_mae: 0.0086 - val_mare: 11.3983\n",
      "Epoch 3/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.5231e-04 - mape: 18.0739 - mae: 0.0089 - mare: 11.7259 - val_loss: 1.4683e-04 - val_mape: 19.7092 - val_mae: 0.0091 - val_mare: 12.0796\n",
      "Epoch 4/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.4737e-04 - mape: 17.4286 - mae: 0.0086 - mare: 11.4156 - val_loss: 1.4341e-04 - val_mape: 18.7475 - val_mae: 0.0088 - val_mare: 11.6323\n",
      "Epoch 5/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.4376e-04 - mape: 17.0451 - mae: 0.0084 - mare: 11.1537 - val_loss: 1.3763e-04 - val_mape: 14.6448 - val_mae: 0.0078 - val_mare: 10.3850\n",
      "Epoch 6/100\n",
      "6806066/6806066 [==============================] - 23s 3us/step - loss: 1.4102e-04 - mape: 16.7476 - mae: 0.0083 - mare: 10.9790 - val_loss: 1.3814e-04 - val_mape: 17.2131 - val_mae: 0.0084 - val_mare: 11.1590\n",
      "Epoch 7/100\n",
      "6806066/6806066 [==============================] - 23s 3us/step - loss: 1.3843e-04 - mape: 16.4163 - mae: 0.0082 - mare: 10.8200 - val_loss: 1.3614e-04 - val_mape: 18.4576 - val_mae: 0.0085 - val_mare: 11.2787\n",
      "Epoch 8/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.3641e-04 - mape: 16.0870 - mae: 0.0081 - mare: 10.6810 - val_loss: 1.3321e-04 - val_mape: 16.4973 - val_mae: 0.0083 - val_mare: 10.9470\n",
      "Epoch 9/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.3451e-04 - mape: 15.9133 - mae: 0.0080 - mare: 10.5484 - val_loss: 1.3871e-04 - val_mape: 23.4827 - val_mae: 0.0096 - val_mare: 12.7721\n",
      "Epoch 10/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.3354e-04 - mape: 15.9301 - mae: 0.0079 - mare: 10.4918 - val_loss: 1.3073e-04 - val_mape: 17.6235 - val_mae: 0.0083 - val_mare: 10.9703\n",
      "Epoch 11/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.3259e-04 - mape: 15.8211 - mae: 0.0079 - mare: 10.4180 - val_loss: 1.3040e-04 - val_mape: 16.4478 - val_mae: 0.0081 - val_mare: 10.7190\n",
      "Epoch 12/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.3178e-04 - mape: 15.6876 - mae: 0.0078 - mare: 10.3464 - val_loss: 1.3006e-04 - val_mape: 14.1943 - val_mae: 0.0077 - val_mare: 10.1730\n",
      "Epoch 13/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.3116e-04 - mape: 15.5932 - mae: 0.0078 - mare: 10.3004 - val_loss: 1.3289e-04 - val_mape: 13.9328 - val_mae: 0.0076 - val_mare: 9.9983\n",
      "Epoch 14/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.3062e-04 - mape: 15.4940 - mae: 0.0077 - mare: 10.2506 - val_loss: 1.2747e-04 - val_mape: 13.9228 - val_mae: 0.0073 - val_mare: 9.7223\n",
      "Epoch 15/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2995e-04 - mape: 15.4662 - mae: 0.0077 - mare: 10.2140 - val_loss: 1.2877e-04 - val_mape: 14.2068 - val_mae: 0.0075 - val_mare: 9.9198\n",
      "Epoch 16/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2932e-04 - mape: 15.3644 - mae: 0.0077 - mare: 10.1677 - val_loss: 1.2623e-04 - val_mape: 15.1501 - val_mae: 0.0076 - val_mare: 10.0627\n",
      "Epoch 17/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2882e-04 - mape: 15.2549 - mae: 0.0076 - mare: 10.1191 - val_loss: 1.2514e-04 - val_mape: 14.3843 - val_mae: 0.0075 - val_mare: 9.9211\n",
      "Epoch 18/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2827e-04 - mape: 15.1767 - mae: 0.0076 - mare: 10.0794 - val_loss: 1.2356e-04 - val_mape: 14.3687 - val_mae: 0.0074 - val_mare: 9.7841\n",
      "Epoch 19/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2794e-04 - mape: 15.1214 - mae: 0.0076 - mare: 10.0495 - val_loss: 1.2596e-04 - val_mape: 14.5759 - val_mae: 0.0074 - val_mare: 9.8044\n",
      "Epoch 20/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2762e-04 - mape: 15.0923 - mae: 0.0076 - mare: 10.0254 - val_loss: 1.2568e-04 - val_mape: 18.7139 - val_mae: 0.0083 - val_mare: 10.9655\n",
      "Epoch 21/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2722e-04 - mape: 15.0393 - mae: 0.0075 - mare: 9.9939 - val_loss: 1.2535e-04 - val_mape: 15.5564 - val_mae: 0.0077 - val_mare: 10.1709\n",
      "Epoch 22/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2701e-04 - mape: 14.9941 - mae: 0.0075 - mare: 9.9765 - val_loss: 1.2304e-04 - val_mape: 14.0185 - val_mae: 0.0073 - val_mare: 9.6349\n",
      "Epoch 23/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2675e-04 - mape: 14.9489 - mae: 0.0075 - mare: 9.9574 - val_loss: 1.2314e-04 - val_mape: 13.5052 - val_mae: 0.0072 - val_mare: 9.5881\n",
      "Epoch 24/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2651e-04 - mape: 14.9003 - mae: 0.0075 - mare: 9.9375 - val_loss: 1.2266e-04 - val_mape: 15.9806 - val_mae: 0.0076 - val_mare: 10.0908\n",
      "Epoch 25/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2622e-04 - mape: 14.8846 - mae: 0.0075 - mare: 9.9212 - val_loss: 1.2266e-04 - val_mape: 14.5097 - val_mae: 0.0073 - val_mare: 9.6810\n",
      "Epoch 26/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2593e-04 - mape: 14.8402 - mae: 0.0075 - mare: 9.8964 - val_loss: 1.2591e-04 - val_mape: 16.6553 - val_mae: 0.0079 - val_mare: 10.3960\n",
      "Epoch 27/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2587e-04 - mape: 14.8574 - mae: 0.0075 - mare: 9.9034 - val_loss: 1.2356e-04 - val_mape: 15.9814 - val_mae: 0.0078 - val_mare: 10.3169\n",
      "Epoch 28/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2566e-04 - mape: 14.7551 - mae: 0.0075 - mare: 9.8776 - val_loss: 1.2607e-04 - val_mape: 16.0059 - val_mae: 0.0077 - val_mare: 10.1699\n",
      "Epoch 29/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2529e-04 - mape: 14.6999 - mae: 0.0074 - mare: 9.8451 - val_loss: 1.2306e-04 - val_mape: 14.2037 - val_mae: 0.0073 - val_mare: 9.7217\n",
      "Epoch 30/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2523e-04 - mape: 14.7105 - mae: 0.0074 - mare: 9.8552 - val_loss: 1.2069e-04 - val_mape: 14.5768 - val_mae: 0.0075 - val_mare: 9.8675\n",
      "Epoch 31/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2501e-04 - mape: 14.7090 - mae: 0.0074 - mare: 9.8302 - val_loss: 1.2399e-04 - val_mape: 17.2679 - val_mae: 0.0079 - val_mare: 10.4858\n",
      "Epoch 32/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2488e-04 - mape: 14.6606 - mae: 0.0074 - mare: 9.8208 - val_loss: 1.2399e-04 - val_mape: 15.1155 - val_mae: 0.0075 - val_mare: 9.9324\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2482e-04 - mape: 14.6494 - mae: 0.0074 - mare: 9.8236 - val_loss: 1.2346e-04 - val_mape: 12.9687 - val_mae: 0.0072 - val_mare: 9.5865\n",
      "Epoch 34/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2463e-04 - mape: 14.5533 - mae: 0.0074 - mare: 9.8035 - val_loss: 1.2335e-04 - val_mape: 18.2832 - val_mae: 0.0081 - val_mare: 10.6624\n",
      "Epoch 35/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2444e-04 - mape: 14.5524 - mae: 0.0074 - mare: 9.8021 - val_loss: 1.2618e-04 - val_mape: 19.9461 - val_mae: 0.0085 - val_mare: 11.2332\n",
      "Epoch 36/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2433e-04 - mape: 14.4586 - mae: 0.0074 - mare: 9.7903 - val_loss: 1.2245e-04 - val_mape: 12.6038 - val_mae: 0.0070 - val_mare: 9.2984\n",
      "Epoch 37/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2423e-04 - mape: 14.4469 - mae: 0.0074 - mare: 9.7767 - val_loss: 1.2083e-04 - val_mape: 14.7910 - val_mae: 0.0075 - val_mare: 9.9352\n",
      "Epoch 38/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 1.2414e-04 - mape: 14.4055 - mae: 0.0074 - mare: 9.7761 - val_loss: 1.2310e-04 - val_mape: 11.7291 - val_mae: 0.0070 - val_mare: 9.3256\n",
      "Epoch 39/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2385e-04 - mape: 14.3457 - mae: 0.0074 - mare: 9.7545 - val_loss: 1.2125e-04 - val_mape: 13.4860 - val_mae: 0.0072 - val_mare: 9.4755\n",
      "Epoch 40/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 1.2383e-04 - mape: 14.3375 - mae: 0.0074 - mare: 9.7485 - val_loss: 1.2143e-04 - val_mape: 14.5922 - val_mae: 0.0073 - val_mare: 9.6933\n",
      "Epoch 41/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 1.2380e-04 - mape: 14.3259 - mae: 0.0074 - mare: 9.7510 - val_loss: 1.1990e-04 - val_mape: 13.1783 - val_mae: 0.0070 - val_mare: 9.3089\n",
      "Epoch 42/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2365e-04 - mape: 14.2841 - mae: 0.0074 - mare: 9.7351 - val_loss: 1.2003e-04 - val_mape: 13.8170 - val_mae: 0.0070 - val_mare: 9.2964\n",
      "Epoch 43/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2359e-04 - mape: 14.3080 - mae: 0.0074 - mare: 9.7373 - val_loss: 1.2032e-04 - val_mape: 12.8156 - val_mae: 0.0071 - val_mare: 9.4132\n",
      "Epoch 44/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2353e-04 - mape: 14.3222 - mae: 0.0074 - mare: 9.7392 - val_loss: 1.2313e-04 - val_mape: 12.4773 - val_mae: 0.0071 - val_mare: 9.4026\n",
      "Epoch 45/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2333e-04 - mape: 14.2366 - mae: 0.0073 - mare: 9.7143 - val_loss: 1.2377e-04 - val_mape: 19.2487 - val_mae: 0.0083 - val_mare: 11.0189\n",
      "Epoch 46/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2327e-04 - mape: 14.2793 - mae: 0.0073 - mare: 9.7136 - val_loss: 1.2465e-04 - val_mape: 13.2279 - val_mae: 0.0075 - val_mare: 9.9287\n",
      "Epoch 47/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2325e-04 - mape: 14.2805 - mae: 0.0073 - mare: 9.7174 - val_loss: 1.1975e-04 - val_mape: 15.2058 - val_mae: 0.0075 - val_mare: 9.8699\n",
      "Epoch 48/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2300e-04 - mape: 14.2171 - mae: 0.0073 - mare: 9.6875 - val_loss: 1.2132e-04 - val_mape: 14.4248 - val_mae: 0.0073 - val_mare: 9.7120\n",
      "Epoch 49/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2303e-04 - mape: 14.2172 - mae: 0.0073 - mare: 9.6933 - val_loss: 1.1918e-04 - val_mape: 14.8599 - val_mae: 0.0074 - val_mare: 9.7840\n",
      "Epoch 50/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2290e-04 - mape: 14.1916 - mae: 0.0073 - mare: 9.6814 - val_loss: 1.1984e-04 - val_mape: 14.9619 - val_mae: 0.0074 - val_mare: 9.7555\n",
      "Epoch 51/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2283e-04 - mape: 14.1996 - mae: 0.0073 - mare: 9.6828 - val_loss: 1.2217e-04 - val_mape: 13.5954 - val_mae: 0.0074 - val_mare: 9.7349\n",
      "Epoch 52/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2269e-04 - mape: 14.1462 - mae: 0.0073 - mare: 9.6596 - val_loss: 1.2770e-04 - val_mape: 15.6701 - val_mae: 0.0080 - val_mare: 10.6173\n",
      "Epoch 53/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2269e-04 - mape: 14.1787 - mae: 0.0073 - mare: 9.6682 - val_loss: 1.1911e-04 - val_mape: 12.8421 - val_mae: 0.0069 - val_mare: 9.1367\n",
      "Epoch 54/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2254e-04 - mape: 14.1774 - mae: 0.0073 - mare: 9.6590 - val_loss: 1.1920e-04 - val_mape: 12.9818 - val_mae: 0.0070 - val_mare: 9.3009\n",
      "Epoch 55/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2256e-04 - mape: 14.1627 - mae: 0.0073 - mare: 9.6625 - val_loss: 1.2127e-04 - val_mape: 15.3976 - val_mae: 0.0076 - val_mare: 10.0018\n",
      "Epoch 56/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2252e-04 - mape: 14.1829 - mae: 0.0073 - mare: 9.6635 - val_loss: 1.2229e-04 - val_mape: 14.4343 - val_mae: 0.0075 - val_mare: 9.8766\n",
      "Epoch 57/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2234e-04 - mape: 14.1078 - mae: 0.0073 - mare: 9.6383 - val_loss: 1.1972e-04 - val_mape: 12.2904 - val_mae: 0.0069 - val_mare: 9.1467\n",
      "Epoch 58/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2242e-04 - mape: 14.1539 - mae: 0.0073 - mare: 9.6545 - val_loss: 1.2097e-04 - val_mape: 13.1351 - val_mae: 0.0072 - val_mare: 9.5439\n",
      "Epoch 59/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2232e-04 - mape: 14.1096 - mae: 0.0073 - mare: 9.6438 - val_loss: 1.2116e-04 - val_mape: 17.3408 - val_mae: 0.0080 - val_mare: 10.5463\n",
      "Epoch 60/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2227e-04 - mape: 14.0918 - mae: 0.0073 - mare: 9.6337 - val_loss: 1.2031e-04 - val_mape: 14.8941 - val_mae: 0.0073 - val_mare: 9.6562\n",
      "Epoch 61/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2217e-04 - mape: 14.0830 - mae: 0.0073 - mare: 9.6269 - val_loss: 1.1909e-04 - val_mape: 12.2910 - val_mae: 0.0069 - val_mare: 9.2006\n",
      "Epoch 62/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2219e-04 - mape: 14.1131 - mae: 0.0073 - mare: 9.6336 - val_loss: 1.1960e-04 - val_mape: 12.8720 - val_mae: 0.0070 - val_mare: 9.2328\n",
      "Epoch 63/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2207e-04 - mape: 14.0872 - mae: 0.0073 - mare: 9.6191 - val_loss: 1.1911e-04 - val_mape: 12.9178 - val_mae: 0.0070 - val_mare: 9.2171\n",
      "Epoch 64/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2199e-04 - mape: 14.0569 - mae: 0.0073 - mare: 9.6135 - val_loss: 1.2007e-04 - val_mape: 11.9842 - val_mae: 0.0070 - val_mare: 9.2754\n",
      "Epoch 65/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2198e-04 - mape: 14.0426 - mae: 0.0073 - mare: 9.6153 - val_loss: 1.2033e-04 - val_mape: 15.7872 - val_mae: 0.0075 - val_mare: 9.9976\n",
      "Epoch 66/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2198e-04 - mape: 14.1029 - mae: 0.0073 - mare: 9.6231 - val_loss: 1.2203e-04 - val_mape: 13.3711 - val_mae: 0.0073 - val_mare: 9.6839\n",
      "Epoch 67/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2184e-04 - mape: 14.0442 - mae: 0.0073 - mare: 9.6035 - val_loss: 1.2430e-04 - val_mape: 18.8719 - val_mae: 0.0082 - val_mare: 10.9060\n",
      "Epoch 68/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2187e-04 - mape: 14.0768 - mae: 0.0073 - mare: 9.6084 - val_loss: 1.1788e-04 - val_mape: 13.0331 - val_mae: 0.0070 - val_mare: 9.2152\n",
      "Epoch 69/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2178e-04 - mape: 14.0373 - mae: 0.0072 - mare: 9.5971 - val_loss: 1.2080e-04 - val_mape: 11.7107 - val_mae: 0.0068 - val_mare: 8.9469\n",
      "Epoch 70/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2178e-04 - mape: 14.0958 - mae: 0.0073 - mare: 9.6039 - val_loss: 1.2100e-04 - val_mape: 12.4276 - val_mae: 0.0070 - val_mare: 9.3072\n",
      "Epoch 71/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2176e-04 - mape: 14.0670 - mae: 0.0072 - mare: 9.6009 - val_loss: 1.1803e-04 - val_mape: 13.7270 - val_mae: 0.0072 - val_mare: 9.5106\n",
      "Epoch 72/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2166e-04 - mape: 14.0905 - mae: 0.0072 - mare: 9.5963 - val_loss: 1.1810e-04 - val_mape: 11.4412 - val_mae: 0.0068 - val_mare: 8.9843\n",
      "Epoch 73/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2169e-04 - mape: 14.0944 - mae: 0.0072 - mare: 9.6006 - val_loss: 1.1802e-04 - val_mape: 12.3219 - val_mae: 0.0069 - val_mare: 9.1421\n",
      "Epoch 74/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2159e-04 - mape: 14.0511 - mae: 0.0072 - mare: 9.5923 - val_loss: 1.1933e-04 - val_mape: 13.3594 - val_mae: 0.0072 - val_mare: 9.5180\n",
      "Epoch 75/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2142e-04 - mape: 14.0182 - mae: 0.0072 - mare: 9.5717 - val_loss: 1.1862e-04 - val_mape: 14.3740 - val_mae: 0.0074 - val_mare: 9.7590\n",
      "Epoch 76/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2155e-04 - mape: 14.0242 - mae: 0.0072 - mare: 9.5819 - val_loss: 1.1830e-04 - val_mape: 14.8302 - val_mae: 0.0074 - val_mare: 9.8639\n",
      "Epoch 77/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2145e-04 - mape: 14.0106 - mae: 0.0072 - mare: 9.5723 - val_loss: 1.1962e-04 - val_mape: 14.1048 - val_mae: 0.0073 - val_mare: 9.6548\n",
      "Epoch 78/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2142e-04 - mape: 14.0091 - mae: 0.0072 - mare: 9.5729 - val_loss: 1.1933e-04 - val_mape: 11.9965 - val_mae: 0.0069 - val_mare: 9.0918\n",
      "Epoch 79/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2137e-04 - mape: 14.0279 - mae: 0.0072 - mare: 9.5712 - val_loss: 1.2158e-04 - val_mape: 11.7103 - val_mae: 0.0069 - val_mare: 9.0706\n",
      "Epoch 80/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2134e-04 - mape: 14.0028 - mae: 0.0072 - mare: 9.5656 - val_loss: 1.1961e-04 - val_mape: 16.4721 - val_mae: 0.0077 - val_mare: 10.1713\n",
      "Epoch 81/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2133e-04 - mape: 14.0002 - mae: 0.0072 - mare: 9.5648 - val_loss: 1.1749e-04 - val_mape: 13.9917 - val_mae: 0.0072 - val_mare: 9.4802\n",
      "Epoch 82/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2129e-04 - mape: 14.0101 - mae: 0.0072 - mare: 9.5673 - val_loss: 1.1838e-04 - val_mape: 13.2660 - val_mae: 0.0071 - val_mare: 9.3459\n",
      "Epoch 83/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2133e-04 - mape: 14.0102 - mae: 0.0072 - mare: 9.5680 - val_loss: 1.1770e-04 - val_mape: 15.8250 - val_mae: 0.0074 - val_mare: 9.8172\n",
      "Epoch 84/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2123e-04 - mape: 13.9835 - mae: 0.0072 - mare: 9.5571 - val_loss: 1.1895e-04 - val_mape: 13.5047 - val_mae: 0.0070 - val_mare: 9.3201\n",
      "Epoch 85/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2113e-04 - mape: 13.9734 - mae: 0.0072 - mare: 9.5479 - val_loss: 1.1869e-04 - val_mape: 11.5593 - val_mae: 0.0068 - val_mare: 8.9966\n",
      "Epoch 86/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2117e-04 - mape: 13.9833 - mae: 0.0072 - mare: 9.5547 - val_loss: 1.1899e-04 - val_mape: 16.1468 - val_mae: 0.0075 - val_mare: 9.9836\n",
      "Epoch 87/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2110e-04 - mape: 13.9810 - mae: 0.0072 - mare: 9.5480 - val_loss: 1.1846e-04 - val_mape: 13.2195 - val_mae: 0.0070 - val_mare: 9.2891\n",
      "Epoch 88/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2113e-04 - mape: 13.9668 - mae: 0.0072 - mare: 9.5528 - val_loss: 1.1894e-04 - val_mape: 14.7257 - val_mae: 0.0074 - val_mare: 9.8177\n",
      "Epoch 89/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 1.2112e-04 - mape: 13.9927 - mae: 0.0072 - mare: 9.5537 - val_loss: 1.2026e-04 - val_mape: 15.6814 - val_mae: 0.0076 - val_mare: 10.0401\n",
      "Epoch 90/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2105e-04 - mape: 13.9475 - mae: 0.0072 - mare: 9.5464 - val_loss: 1.2007e-04 - val_mape: 14.6095 - val_mae: 0.0074 - val_mare: 9.7344\n",
      "Epoch 91/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2097e-04 - mape: 13.9593 - mae: 0.0072 - mare: 9.5428 - val_loss: 1.1808e-04 - val_mape: 11.7764 - val_mae: 0.0068 - val_mare: 8.9389\n",
      "Epoch 92/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2100e-04 - mape: 13.9766 - mae: 0.0072 - mare: 9.5398 - val_loss: 1.1888e-04 - val_mape: 13.3705 - val_mae: 0.0072 - val_mare: 9.5729\n",
      "Epoch 93/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2092e-04 - mape: 13.9313 - mae: 0.0072 - mare: 9.5314 - val_loss: 1.1790e-04 - val_mape: 12.1250 - val_mae: 0.0068 - val_mare: 9.0437\n",
      "Epoch 94/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2088e-04 - mape: 13.9442 - mae: 0.0072 - mare: 9.5301 - val_loss: 1.1717e-04 - val_mape: 11.9872 - val_mae: 0.0068 - val_mare: 8.9886\n",
      "Epoch 95/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2088e-04 - mape: 13.9523 - mae: 0.0072 - mare: 9.5334 - val_loss: 1.1800e-04 - val_mape: 12.6632 - val_mae: 0.0069 - val_mare: 9.1365\n",
      "Epoch 96/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2088e-04 - mape: 13.9520 - mae: 0.0072 - mare: 9.5347 - val_loss: 1.1781e-04 - val_mape: 12.7724 - val_mae: 0.0070 - val_mare: 9.2900\n",
      "Epoch 97/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2083e-04 - mape: 13.9419 - mae: 0.0072 - mare: 9.5292 - val_loss: 1.2351e-04 - val_mape: 18.1743 - val_mae: 0.0083 - val_mare: 10.9751\n",
      "Epoch 98/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2085e-04 - mape: 13.9224 - mae: 0.0072 - mare: 9.5237 - val_loss: 1.1877e-04 - val_mape: 12.0673 - val_mae: 0.0069 - val_mare: 9.1292\n",
      "Epoch 99/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2077e-04 - mape: 13.9143 - mae: 0.0072 - mare: 9.5171 - val_loss: 1.1884e-04 - val_mape: 12.1273 - val_mae: 0.0069 - val_mare: 9.1457\n",
      "Epoch 100/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 1.2077e-04 - mape: 13.9312 - mae: 0.0072 - mare: 9.5218 - val_loss: 1.1731e-04 - val_mape: 12.6031 - val_mae: 0.0069 - val_mare: 9.1820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20b480e0c18>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_distance_model(alpha = 0):\n",
    "    \n",
    "    input_layer = Input(shape=(4,), name = 'input')\n",
    "    \n",
    "    hidden_layer = Dense(20, name = 'shared_dense1', activation  = 'relu')(input_layer)\n",
    "    hidden_layer = Dense(100, name = 'shared_dense2', activation  = 'relu')(hidden_layer)\n",
    "    hidden_layer = Dense(20, name = 'shared_dense3', activation  = 'relu')(hidden_layer)\n",
    "\n",
    "    output_layer = Dense(1, name = 'distance')(hidden_layer)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    opt = optimizers.Adam(lr=0.001)\n",
    "    \n",
    "    model.compile(loss=huber_loss,\n",
    "                  optimizer=opt,\n",
    "                  metrics=[mape, mae, mare])\n",
    "    return model\n",
    "\n",
    "dist_dnn_model = build_distance_model()\n",
    "print(dist_dnn_model.summary())\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "time_stamp = time()\n",
    "print('Time stamp:', time_stamp)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='tb_logs/dist_dnn_{}'.format(time_stamp))\n",
    "\n",
    "dist_dnn_model.fit(x=train_input[:,:4],\n",
    "          y=train_output[:,1],\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          validation_data=(valid_input[:,:4],valid_output[:,1]),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to disk.\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model_json = dist_dnn_model.to_json()\n",
    "with open(\"../keras_models/dist_dnn_model_{}.json\".format(time_stamp), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "dist_dnn_model.save_weights(\"../keras_models/dist_dnn_model_{}.h5\".format(time_stamp))\n",
    "print(\"Model saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972296/972296 [==============================] - 1s 1us/step\n",
      "[LOSS, MAPE, MAE, MARE] = [0.00012102204146875933, 12.70515461608001, 0.0069249589306288415, 9.186677569990383]\n"
     ]
    }
   ],
   "source": [
    "score = dist_dnn_model.evaluate(test_input[:,:4], test_output[:,1], batch_size=BATCH_SIZE)\n",
    "print('[LOSS, MAPE, MAE, MARE] =', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DURATION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "model = ...  # include here your original model\n",
    "\n",
    "layer_name = 'shared_dense3'\n",
    "intermediate_layer_model = Model(inputs=dist_dnn_model.input,\n",
    "                                 outputs=dist_dnn_model.get_layer(layer_name).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_last_hidden_train = intermediate_layer_model.predict(train_input[:,:4])\n",
    "dist_last_hidden_valid = intermediate_layer_model.predict(valid_input[:,:4])\n",
    "dist_last_hidden_test = intermediate_layer_model.predict(test_input[:,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "#filename = 'finalized_model.sav'\n",
    "#joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(dist_last_hidden_train, open('dist_last_hidden_train.dat', 'wb'))\n",
    "joblib.dump(dist_last_hidden_valid, open('dist_last_hidden_valid.dat', 'wb'))\n",
    "joblib.dump(dist_last_hidden_test, open('dist_last_hidden_test.dat', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_last_hidden_train = joblib.load('dist_last_hidden_train.dat')\n",
    "dist_last_hidden_valid = joblib.load('dist_last_hidden_valid.dat')\n",
    "dist_last_hidden_test = joblib.load('dist_last_hidden_test.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6806066, 20)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_last_hidden_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_train = np.hstack((dist_last_hidden_train[:], train_input[:][:,5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_valid = np.hstack((dist_last_hidden_valid[:], valid_input[:][:,5:]))\n",
    "concatenated_test  = np.hstack((dist_last_hidden_test[:], test_input[:][:,5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(972296, 24)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arthur\\Miniconda3\\envs\\general\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Arthur\\Miniconda3\\envs\\general\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:448: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "shared_dense1 (Dense)        (None, 20)                500       \n",
      "_________________________________________________________________\n",
      "shared_dense2 (Dense)        (None, 100)               2100      \n",
      "_________________________________________________________________\n",
      "shared_dense3 (Dense)        (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "duration (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 4,641\n",
      "Trainable params: 4,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Time stamp: 1554911866.9540386\n",
      "Train on 6806066 samples, validate on 1944590 samples\n",
      "Epoch 1/100\n",
      "6806066/6806066 [==============================] - 28s 4us/step - loss: 0.0010 - mape: 33.1127 - mae: 0.0294 - mare: 24.2027 - val_loss: 9.4816e-04 - val_mape: 28.0501 - val_mae: 0.0274 - val_mare: 22.5936\n",
      "Epoch 2/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 9.1061e-04 - mape: 30.6021 - mae: 0.0277 - mare: 22.8508 - val_loss: 8.9416e-04 - val_mape: 28.2371 - val_mae: 0.0269 - val_mare: 22.2003\n",
      "Epoch 3/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.8929e-04 - mape: 30.0536 - mae: 0.0273 - mare: 22.5125 - val_loss: 8.7766e-04 - val_mape: 28.7487 - val_mae: 0.0268 - val_mare: 22.0457\n",
      "Epoch 4/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.7659e-04 - mape: 29.7439 - mae: 0.0271 - mare: 22.3162 - val_loss: 8.7308e-04 - val_mape: 32.1040 - val_mae: 0.0277 - val_mare: 22.7928\n",
      "Epoch 5/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.6847e-04 - mape: 29.5416 - mae: 0.0269 - mare: 22.1875 - val_loss: 8.6084e-04 - val_mape: 29.0343 - val_mae: 0.0268 - val_mare: 22.0619\n",
      "Epoch 6/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.6230e-04 - mape: 29.4051 - mae: 0.0268 - mare: 22.0882 - val_loss: 8.5651e-04 - val_mape: 30.7910 - val_mae: 0.0270 - val_mare: 22.2689\n",
      "Epoch 7/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.5765e-04 - mape: 29.2753 - mae: 0.0267 - mare: 22.0136 - val_loss: 8.4917e-04 - val_mape: 29.7000 - val_mae: 0.0268 - val_mare: 22.0866\n",
      "Epoch 8/100\n",
      "6806066/6806066 [==============================] - 23s 3us/step - loss: 8.5402e-04 - mape: 29.1821 - mae: 0.0266 - mare: 21.9539 - val_loss: 8.5339e-04 - val_mape: 29.1398 - val_mae: 0.0267 - val_mare: 21.9621\n",
      "Epoch 9/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.5067e-04 - mape: 29.0799 - mae: 0.0266 - mare: 21.8917 - val_loss: 8.4302e-04 - val_mape: 28.6370 - val_mae: 0.0264 - val_mare: 21.7821\n",
      "Epoch 10/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.4777e-04 - mape: 28.9925 - mae: 0.0265 - mare: 21.8465 - val_loss: 8.4054e-04 - val_mape: 28.1140 - val_mae: 0.0263 - val_mare: 21.6706\n",
      "Epoch 11/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.4498e-04 - mape: 28.9227 - mae: 0.0264 - mare: 21.7984 - val_loss: 8.4726e-04 - val_mape: 26.5807 - val_mae: 0.0261 - val_mare: 21.4707\n",
      "Epoch 12/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.4343e-04 - mape: 28.8707 - mae: 0.0264 - mare: 21.7742 - val_loss: 8.3596e-04 - val_mape: 28.7920 - val_mae: 0.0263 - val_mare: 21.6848\n",
      "Epoch 13/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.4138e-04 - mape: 28.8103 - mae: 0.0264 - mare: 21.7372 - val_loss: 8.5067e-04 - val_mape: 32.3505 - val_mae: 0.0274 - val_mare: 22.6105\n",
      "Epoch 14/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.4022e-04 - mape: 28.7858 - mae: 0.0264 - mare: 21.7202 - val_loss: 8.3528e-04 - val_mape: 28.1424 - val_mae: 0.0262 - val_mare: 21.5979\n",
      "Epoch 15/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.3879e-04 - mape: 28.7439 - mae: 0.0263 - mare: 21.6951 - val_loss: 8.4094e-04 - val_mape: 31.4887 - val_mae: 0.0270 - val_mare: 22.2618\n",
      "Epoch 16/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.3776e-04 - mape: 28.7293 - mae: 0.0263 - mare: 21.6815 - val_loss: 8.3399e-04 - val_mape: 28.8220 - val_mae: 0.0263 - val_mare: 21.6802\n",
      "Epoch 17/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.3680e-04 - mape: 28.7140 - mae: 0.0263 - mare: 21.6680 - val_loss: 8.3429e-04 - val_mape: 29.9130 - val_mae: 0.0266 - val_mare: 21.9219\n",
      "Epoch 18/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.3593e-04 - mape: 28.6781 - mae: 0.0263 - mare: 21.6516 - val_loss: 8.4566e-04 - val_mape: 31.7861 - val_mae: 0.0270 - val_mare: 22.2207\n",
      "Epoch 19/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.3508e-04 - mape: 28.6476 - mae: 0.0262 - mare: 21.6345 - val_loss: 8.3764e-04 - val_mape: 30.5297 - val_mae: 0.0268 - val_mare: 22.1018\n",
      "Epoch 20/100\n",
      "6806066/6806066 [==============================] - 23s 3us/step - loss: 8.3432e-04 - mape: 28.6426 - mae: 0.0262 - mare: 21.6246 - val_loss: 8.3426e-04 - val_mape: 28.7570 - val_mae: 0.0264 - val_mare: 21.7217\n",
      "Epoch 21/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.3401e-04 - mape: 28.6428 - mae: 0.0262 - mare: 21.6196 - val_loss: 8.3850e-04 - val_mape: 30.1719 - val_mae: 0.0267 - val_mare: 22.0269\n",
      "Epoch 22/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.3306e-04 - mape: 28.6132 - mae: 0.0262 - mare: 21.6016 - val_loss: 8.3166e-04 - val_mape: 26.7598 - val_mae: 0.0258 - val_mare: 21.2630\n",
      "Epoch 23/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.3287e-04 - mape: 28.6095 - mae: 0.0262 - mare: 21.5998 - val_loss: 8.3374e-04 - val_mape: 30.7397 - val_mae: 0.0268 - val_mare: 22.1217\n",
      "Epoch 24/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.3199e-04 - mape: 28.5735 - mae: 0.0262 - mare: 21.5865 - val_loss: 8.2676e-04 - val_mape: 27.4768 - val_mae: 0.0259 - val_mare: 21.3498\n",
      "Epoch 25/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.3171e-04 - mape: 28.5658 - mae: 0.0262 - mare: 21.5793 - val_loss: 8.3041e-04 - val_mape: 26.9171 - val_mae: 0.0258 - val_mare: 21.2387\n",
      "Epoch 26/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.3145e-04 - mape: 28.5560 - mae: 0.0262 - mare: 21.5744 - val_loss: 8.2918e-04 - val_mape: 28.3659 - val_mae: 0.0262 - val_mare: 21.6031\n",
      "Epoch 27/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.3053e-04 - mape: 28.5198 - mae: 0.0262 - mare: 21.5587 - val_loss: 8.2935e-04 - val_mape: 27.7099 - val_mae: 0.0260 - val_mare: 21.4017\n",
      "Epoch 28/100\n",
      "6806066/6806066 [==============================] - 23s 3us/step - loss: 8.3060e-04 - mape: 28.5243 - mae: 0.0262 - mare: 21.5617 - val_loss: 8.3823e-04 - val_mape: 27.7760 - val_mae: 0.0262 - val_mare: 21.5645\n",
      "Epoch 29/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2971e-04 - mape: 28.4963 - mae: 0.0261 - mare: 21.5462 - val_loss: 8.2717e-04 - val_mape: 27.2778 - val_mae: 0.0259 - val_mare: 21.3273\n",
      "Epoch 30/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2965e-04 - mape: 28.4946 - mae: 0.0261 - mare: 21.5450 - val_loss: 8.2782e-04 - val_mape: 26.7532 - val_mae: 0.0257 - val_mare: 21.1785\n",
      "Epoch 31/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2927e-04 - mape: 28.4826 - mae: 0.0261 - mare: 21.5369 - val_loss: 8.2515e-04 - val_mape: 29.6594 - val_mae: 0.0263 - val_mare: 21.6988\n",
      "Epoch 32/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2883e-04 - mape: 28.4744 - mae: 0.0261 - mare: 21.5314 - val_loss: 8.3555e-04 - val_mape: 31.6308 - val_mae: 0.0269 - val_mare: 22.1743\n",
      "Epoch 33/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2847e-04 - mape: 28.4625 - mae: 0.0261 - mare: 21.5235 - val_loss: 8.2875e-04 - val_mape: 30.1741 - val_mae: 0.0267 - val_mare: 21.9634\n",
      "Epoch 34/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2833e-04 - mape: 28.4653 - mae: 0.0261 - mare: 21.5246 - val_loss: 8.3237e-04 - val_mape: 31.4393 - val_mae: 0.0269 - val_mare: 22.1604\n",
      "Epoch 35/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2781e-04 - mape: 28.4544 - mae: 0.0261 - mare: 21.5142 - val_loss: 8.3548e-04 - val_mape: 28.1543 - val_mae: 0.0263 - val_mare: 21.6865\n",
      "Epoch 36/100\n",
      "6806066/6806066 [==============================] - 23s 3us/step - loss: 8.2746e-04 - mape: 28.4266 - mae: 0.0261 - mare: 21.5078 - val_loss: 8.2658e-04 - val_mape: 28.8406 - val_mae: 0.0262 - val_mare: 21.5823\n",
      "Epoch 37/100\n",
      "6806066/6806066 [==============================] - 23s 3us/step - loss: 8.2717e-04 - mape: 28.4235 - mae: 0.0261 - mare: 21.5060 - val_loss: 8.2397e-04 - val_mape: 27.8737 - val_mae: 0.0258 - val_mare: 21.2494\n",
      "Epoch 38/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2695e-04 - mape: 28.4321 - mae: 0.0261 - mare: 21.5024 - val_loss: 8.2221e-04 - val_mape: 27.3760 - val_mae: 0.0259 - val_mare: 21.3364\n",
      "Epoch 39/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2673e-04 - mape: 28.4239 - mae: 0.0261 - mare: 21.4986 - val_loss: 8.2785e-04 - val_mape: 29.0935 - val_mae: 0.0261 - val_mare: 21.5069\n",
      "Epoch 40/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2665e-04 - mape: 28.4297 - mae: 0.0261 - mare: 21.4953 - val_loss: 8.2915e-04 - val_mape: 28.2342 - val_mae: 0.0258 - val_mare: 21.2856\n",
      "Epoch 41/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2617e-04 - mape: 28.4151 - mae: 0.0261 - mare: 21.4864 - val_loss: 8.3744e-04 - val_mape: 25.8063 - val_mae: 0.0257 - val_mare: 21.1517\n",
      "Epoch 42/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2578e-04 - mape: 28.4164 - mae: 0.0261 - mare: 21.4827 - val_loss: 8.2743e-04 - val_mape: 26.6215 - val_mae: 0.0258 - val_mare: 21.2418\n",
      "Epoch 43/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2571e-04 - mape: 28.4099 - mae: 0.0261 - mare: 21.4794 - val_loss: 8.2372e-04 - val_mape: 26.8165 - val_mae: 0.0257 - val_mare: 21.2137\n",
      "Epoch 44/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2532e-04 - mape: 28.3997 - mae: 0.0261 - mare: 21.4757 - val_loss: 8.2874e-04 - val_mape: 28.0230 - val_mae: 0.0262 - val_mare: 21.5868\n",
      "Epoch 45/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2521e-04 - mape: 28.4049 - mae: 0.0261 - mare: 21.4753 - val_loss: 8.2587e-04 - val_mape: 29.1052 - val_mae: 0.0264 - val_mare: 21.7387\n",
      "Epoch 46/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2517e-04 - mape: 28.3923 - mae: 0.0260 - mare: 21.4719 - val_loss: 8.2303e-04 - val_mape: 28.0611 - val_mae: 0.0259 - val_mare: 21.3641\n",
      "Epoch 47/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2470e-04 - mape: 28.3845 - mae: 0.0260 - mare: 21.4645 - val_loss: 8.2398e-04 - val_mape: 28.1746 - val_mae: 0.0260 - val_mare: 21.3949\n",
      "Epoch 48/100\n",
      "6806066/6806066 [==============================] - 24s 3us/step - loss: 8.2456e-04 - mape: 28.3811 - mae: 0.0260 - mare: 21.4608 - val_loss: 8.2122e-04 - val_mape: 28.7095 - val_mae: 0.0261 - val_mare: 21.5201\n",
      "Epoch 49/100\n",
      "6806066/6806066 [==============================] - 23s 3us/step - loss: 8.2443e-04 - mape: 28.3833 - mae: 0.0260 - mare: 21.4599 - val_loss: 8.2672e-04 - val_mape: 31.0057 - val_mae: 0.0267 - val_mare: 21.9956\n",
      "Epoch 50/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2404e-04 - mape: 28.3722 - mae: 0.0260 - mare: 21.4535 - val_loss: 8.2385e-04 - val_mape: 26.8725 - val_mae: 0.0256 - val_mare: 21.1201\n",
      "Epoch 51/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2399e-04 - mape: 28.3671 - mae: 0.0260 - mare: 21.4525 - val_loss: 8.2298e-04 - val_mape: 28.9343 - val_mae: 0.0263 - val_mare: 21.6348\n",
      "Epoch 52/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2382e-04 - mape: 28.3734 - mae: 0.0260 - mare: 21.4477 - val_loss: 8.3266e-04 - val_mape: 31.3845 - val_mae: 0.0268 - val_mare: 22.1242\n",
      "Epoch 53/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2344e-04 - mape: 28.3509 - mae: 0.0260 - mare: 21.4444 - val_loss: 8.3497e-04 - val_mape: 30.3819 - val_mae: 0.0269 - val_mare: 22.1433\n",
      "Epoch 54/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2344e-04 - mape: 28.3495 - mae: 0.0260 - mare: 21.4412 - val_loss: 8.2554e-04 - val_mape: 26.9907 - val_mae: 0.0257 - val_mare: 21.1572\n",
      "Epoch 55/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2325e-04 - mape: 28.3528 - mae: 0.0260 - mare: 21.4416 - val_loss: 8.2235e-04 - val_mape: 28.0075 - val_mae: 0.0260 - val_mare: 21.3844\n",
      "Epoch 56/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2302e-04 - mape: 28.3412 - mae: 0.0260 - mare: 21.4345 - val_loss: 8.2993e-04 - val_mape: 31.3390 - val_mae: 0.0266 - val_mare: 21.9579\n",
      "Epoch 57/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2291e-04 - mape: 28.3441 - mae: 0.0260 - mare: 21.4338 - val_loss: 8.2482e-04 - val_mape: 26.7454 - val_mae: 0.0256 - val_mare: 21.0710\n",
      "Epoch 58/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2278e-04 - mape: 28.3275 - mae: 0.0260 - mare: 21.4295 - val_loss: 8.2764e-04 - val_mape: 28.5004 - val_mae: 0.0264 - val_mare: 21.7229\n",
      "Epoch 59/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2276e-04 - mape: 28.3460 - mae: 0.0260 - mare: 21.4321 - val_loss: 8.2231e-04 - val_mape: 26.9066 - val_mae: 0.0258 - val_mare: 21.2339\n",
      "Epoch 60/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2248e-04 - mape: 28.3271 - mae: 0.0260 - mare: 21.4239 - val_loss: 8.1854e-04 - val_mape: 28.2344 - val_mae: 0.0259 - val_mare: 21.3592\n",
      "Epoch 61/100\n",
      "6806066/6806066 [==============================] - 23s 3us/step - loss: 8.2209e-04 - mape: 28.3049 - mae: 0.0260 - mare: 21.4180 - val_loss: 8.2301e-04 - val_mape: 29.1934 - val_mae: 0.0264 - val_mare: 21.7313\n",
      "Epoch 62/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2192e-04 - mape: 28.3114 - mae: 0.0260 - mare: 21.4154 - val_loss: 8.2434e-04 - val_mape: 27.0612 - val_mae: 0.0258 - val_mare: 21.2477\n",
      "Epoch 63/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2204e-04 - mape: 28.3151 - mae: 0.0260 - mare: 21.4174 - val_loss: 8.2246e-04 - val_mape: 29.8565 - val_mae: 0.0264 - val_mare: 21.7320\n",
      "Epoch 64/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2182e-04 - mape: 28.3181 - mae: 0.0260 - mare: 21.4180 - val_loss: 8.2369e-04 - val_mape: 27.7852 - val_mae: 0.0260 - val_mare: 21.4255\n",
      "Epoch 65/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2155e-04 - mape: 28.2984 - mae: 0.0260 - mare: 21.4114 - val_loss: 8.2246e-04 - val_mape: 28.5128 - val_mae: 0.0259 - val_mare: 21.3250\n",
      "Epoch 66/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2129e-04 - mape: 28.2987 - mae: 0.0260 - mare: 21.4077 - val_loss: 8.2183e-04 - val_mape: 27.5124 - val_mae: 0.0259 - val_mare: 21.3390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2127e-04 - mape: 28.2986 - mae: 0.0260 - mare: 21.4068 - val_loss: 8.3088e-04 - val_mape: 31.9472 - val_mae: 0.0270 - val_mare: 22.2696\n",
      "Epoch 68/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2125e-04 - mape: 28.2904 - mae: 0.0260 - mare: 21.4076 - val_loss: 8.2496e-04 - val_mape: 28.1090 - val_mae: 0.0257 - val_mare: 21.1848\n",
      "Epoch 69/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2117e-04 - mape: 28.3034 - mae: 0.0260 - mare: 21.4058 - val_loss: 8.2145e-04 - val_mape: 30.1455 - val_mae: 0.0265 - val_mare: 21.8224\n",
      "Epoch 70/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2070e-04 - mape: 28.2853 - mae: 0.0260 - mare: 21.3984 - val_loss: 8.2130e-04 - val_mape: 27.1480 - val_mae: 0.0256 - val_mare: 21.0737\n",
      "Epoch 71/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2094e-04 - mape: 28.2941 - mae: 0.0260 - mare: 21.4014 - val_loss: 8.2204e-04 - val_mape: 26.7600 - val_mae: 0.0259 - val_mare: 21.3111\n",
      "Epoch 72/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2075e-04 - mape: 28.2933 - mae: 0.0260 - mare: 21.3992 - val_loss: 8.1991e-04 - val_mape: 27.4492 - val_mae: 0.0257 - val_mare: 21.1453\n",
      "Epoch 73/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2067e-04 - mape: 28.2860 - mae: 0.0260 - mare: 21.3989 - val_loss: 8.2319e-04 - val_mape: 28.8403 - val_mae: 0.0262 - val_mare: 21.6242\n",
      "Epoch 74/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2072e-04 - mape: 28.2901 - mae: 0.0260 - mare: 21.3999 - val_loss: 8.2358e-04 - val_mape: 29.6419 - val_mae: 0.0264 - val_mare: 21.7526\n",
      "Epoch 75/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2055e-04 - mape: 28.2873 - mae: 0.0260 - mare: 21.3959 - val_loss: 8.2151e-04 - val_mape: 29.2590 - val_mae: 0.0262 - val_mare: 21.6033\n",
      "Epoch 76/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2029e-04 - mape: 28.2755 - mae: 0.0260 - mare: 21.3940 - val_loss: 8.2263e-04 - val_mape: 27.2446 - val_mae: 0.0256 - val_mare: 21.1210\n",
      "Epoch 77/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.2014e-04 - mape: 28.2651 - mae: 0.0259 - mare: 21.3873 - val_loss: 8.1913e-04 - val_mape: 28.3574 - val_mae: 0.0260 - val_mare: 21.3837\n",
      "Epoch 78/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2006e-04 - mape: 28.2650 - mae: 0.0259 - mare: 21.3870 - val_loss: 8.2813e-04 - val_mape: 30.3448 - val_mae: 0.0266 - val_mare: 21.9301\n",
      "Epoch 79/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.1990e-04 - mape: 28.2634 - mae: 0.0259 - mare: 21.3865 - val_loss: 8.1968e-04 - val_mape: 27.4086 - val_mae: 0.0256 - val_mare: 21.1085\n",
      "Epoch 80/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.2001e-04 - mape: 28.2775 - mae: 0.0259 - mare: 21.3869 - val_loss: 8.1869e-04 - val_mape: 27.6299 - val_mae: 0.0258 - val_mare: 21.2372\n",
      "Epoch 81/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.1941e-04 - mape: 28.2422 - mae: 0.0259 - mare: 21.3750 - val_loss: 8.2214e-04 - val_mape: 28.1344 - val_mae: 0.0261 - val_mare: 21.4919\n",
      "Epoch 82/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.1981e-04 - mape: 28.2630 - mae: 0.0259 - mare: 21.3840 - val_loss: 8.2807e-04 - val_mape: 31.6286 - val_mae: 0.0269 - val_mare: 22.1504\n",
      "Epoch 83/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.1946e-04 - mape: 28.2579 - mae: 0.0259 - mare: 21.3792 - val_loss: 8.2213e-04 - val_mape: 29.5432 - val_mae: 0.0264 - val_mare: 21.7396\n",
      "Epoch 84/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.1958e-04 - mape: 28.2587 - mae: 0.0259 - mare: 21.3797 - val_loss: 8.1990e-04 - val_mape: 26.6635 - val_mae: 0.0257 - val_mare: 21.1467\n",
      "Epoch 85/100\n",
      "6806066/6806066 [==============================] - 23s 3us/step - loss: 8.1944e-04 - mape: 28.2477 - mae: 0.0259 - mare: 21.3769 - val_loss: 8.2826e-04 - val_mape: 30.7073 - val_mae: 0.0267 - val_mare: 22.0294\n",
      "Epoch 86/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.1968e-04 - mape: 28.2666 - mae: 0.0259 - mare: 21.3804 - val_loss: 8.2093e-04 - val_mape: 27.0570 - val_mae: 0.0258 - val_mare: 21.2777\n",
      "Epoch 87/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.1934e-04 - mape: 28.2532 - mae: 0.0259 - mare: 21.3743 - val_loss: 8.1900e-04 - val_mape: 28.6845 - val_mae: 0.0261 - val_mare: 21.4975\n",
      "Epoch 88/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.1922e-04 - mape: 28.2567 - mae: 0.0259 - mare: 21.3766 - val_loss: 8.1812e-04 - val_mape: 27.7566 - val_mae: 0.0259 - val_mare: 21.3118\n",
      "Epoch 89/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.1919e-04 - mape: 28.2522 - mae: 0.0259 - mare: 21.3730 - val_loss: 8.1652e-04 - val_mape: 27.3451 - val_mae: 0.0257 - val_mare: 21.1780\n",
      "Epoch 90/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.1926e-04 - mape: 28.2366 - mae: 0.0259 - mare: 21.3737 - val_loss: 8.1648e-04 - val_mape: 28.5998 - val_mae: 0.0259 - val_mare: 21.3766\n",
      "Epoch 91/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.1908e-04 - mape: 28.2395 - mae: 0.0259 - mare: 21.3709 - val_loss: 8.2720e-04 - val_mape: 27.2964 - val_mae: 0.0261 - val_mare: 21.4682\n",
      "Epoch 92/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.1881e-04 - mape: 28.2197 - mae: 0.0259 - mare: 21.3623 - val_loss: 8.2298e-04 - val_mape: 29.0258 - val_mae: 0.0264 - val_mare: 21.7223\n",
      "Epoch 93/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.1884e-04 - mape: 28.2213 - mae: 0.0259 - mare: 21.3669 - val_loss: 8.1777e-04 - val_mape: 27.4136 - val_mae: 0.0256 - val_mare: 21.0992\n",
      "Epoch 94/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.1907e-04 - mape: 28.2400 - mae: 0.0259 - mare: 21.3704 - val_loss: 8.1703e-04 - val_mape: 28.8964 - val_mae: 0.0261 - val_mare: 21.4823\n",
      "Epoch 95/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.1883e-04 - mape: 28.2388 - mae: 0.0259 - mare: 21.3660 - val_loss: 8.2859e-04 - val_mape: 25.9481 - val_mae: 0.0254 - val_mare: 20.8975\n",
      "Epoch 96/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.1867e-04 - mape: 28.2240 - mae: 0.0259 - mare: 21.3634 - val_loss: 8.1944e-04 - val_mape: 27.3940 - val_mae: 0.0257 - val_mare: 21.1637\n",
      "Epoch 97/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.1849e-04 - mape: 28.2214 - mae: 0.0259 - mare: 21.3622 - val_loss: 8.1636e-04 - val_mape: 27.5066 - val_mae: 0.0258 - val_mare: 21.2664\n",
      "Epoch 98/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.1872e-04 - mape: 28.2284 - mae: 0.0259 - mare: 21.3618 - val_loss: 8.2392e-04 - val_mape: 26.1615 - val_mae: 0.0254 - val_mare: 20.9443\n",
      "Epoch 99/100\n",
      "6806066/6806066 [==============================] - 21s 3us/step - loss: 8.1856e-04 - mape: 28.2079 - mae: 0.0259 - mare: 21.3605 - val_loss: 8.1798e-04 - val_mape: 29.9398 - val_mae: 0.0263 - val_mare: 21.6460\n",
      "Epoch 100/100\n",
      "6806066/6806066 [==============================] - 22s 3us/step - loss: 8.1843e-04 - mape: 28.2093 - mae: 0.0259 - mare: 21.3594 - val_loss: 8.1913e-04 - val_mape: 28.2146 - val_mae: 0.0260 - val_mare: 21.4152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1960afb9ba8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_duration_model(alpha = 0):\n",
    "    \n",
    "    input_layer = Input(shape=(24,), name = 'input')\n",
    "    \n",
    "    hidden_layer = Dense(20, name = 'shared_dense1', activation  = 'relu')(input_layer)\n",
    "    hidden_layer = Dense(100, name = 'shared_dense2', activation  = 'relu')(hidden_layer)\n",
    "    hidden_layer = Dense(20, name = 'shared_dense3', activation  = 'relu')(hidden_layer)\n",
    "\n",
    "    output_layer = Dense(1, name = 'duration')(hidden_layer)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    opt = optimizers.Adam(lr=0.001)\n",
    "    \n",
    "    model.compile(loss=huber_loss,\n",
    "                  optimizer=opt,\n",
    "                  metrics=[mape, mae, mare])\n",
    "    return model\n",
    "\n",
    "dur_dnn_model = build_duration_model()\n",
    "print(dur_dnn_model.summary())\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "time_stamp = time()\n",
    "print('Time stamp:', time_stamp)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='tb_logs/dur_dnn_{}'.format(time_stamp))\n",
    "\n",
    "dur_dnn_model.fit(x=concatenated_train,\n",
    "          y=train_output[:,0],\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          validation_data=(concatenated_valid,valid_output[:,0]),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to disk.\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model_json = dur_dnn_model.to_json()\n",
    "with open(\"../keras_models/dur_dnn_model_{}.json\".format(time_stamp), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "dur_dnn_model.save_weights(\"../keras_models/dur_dnn_model_{}.h5\".format(time_stamp))\n",
    "print(\"Model saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972296/972296 [==============================] - 1s 1us/step\n",
      "[LOSS, MAPE, MAE, MARE] = [0.0008172396679645793, 28.353376294969085, 0.025961281781165593, 21.413368870746552]\n"
     ]
    }
   ],
   "source": [
    "score = dur_dnn_model.evaluate(concatenated_test, test_output[:,0], batch_size=BATCH_SIZE)\n",
    "print('[LOSS, MAPE, MAE, MARE] =', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISTANCE & DURATION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 4)            0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "shared_dense1 (Dense)           (None, 20)           100         lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "shared_dense2 (Dense)           (None, 100)          2100        shared_dense1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "shared_dense3 (Dense)           (None, 20)           2020        shared_dense2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 4)            0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dur_input (Concatenate)         (None, 24)           0           shared_dense3[0][0]              \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "shared1_dense1 (Dense)          (None, 20)           500         dur_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "shared1_dense2 (Dense)          (None, 100)          2100        shared1_dense1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "shared1_dense3 (Dense)          (None, 20)           2020        shared1_dense2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "duration (Dense)                (None, 1)            21          shared1_dense3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "distance (Dense)                (None, 1)            21          shared_dense3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,882\n",
      "Trainable params: 8,882\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_dist_dur_model(alpha = 0):\n",
    "    \n",
    "    input_layer = Input(shape=(8,), name = 'input')\n",
    "    \n",
    "    group1_spatial  = Lambda(lambda x: x[:,:4], output_shape=((4,)))(input_layer)\n",
    "    group2_temporal = Lambda(lambda x: x[:,4:8], output_shape=((4,)))(input_layer)\n",
    "    \n",
    "    # DIST MODULE\n",
    "    hidden_layer = Dense(20, name = 'shared_dense1', activation  = 'relu')(group1_spatial)\n",
    "    hidden_layer = Dense(100, name = 'shared_dense2', activation  = 'relu')(hidden_layer)\n",
    "    hidden_layer = Dense(20, name = 'shared_dense3', activation  = 'relu')(hidden_layer)\n",
    "    output_dist_layer = Dense(1, name = 'distance')(hidden_layer)\n",
    "\n",
    "    # CONCATENATE HIDDEN_LAYER TO GROUP2\n",
    "    dur_module_input = Concatenate(name='dur_input')([hidden_layer,group2_temporal]) # Should have 24 for shape\n",
    "     \n",
    "    hidden_layer1 = Dense(20, name = 'shared1_dense1', activation  = 'relu')(dur_module_input)\n",
    "    hidden_layer1 = Dense(100, name = 'shared1_dense2', activation  = 'relu')(hidden_layer1)\n",
    "    hidden_layer1 = Dense(20, name = 'shared1_dense3', activation  = 'relu')(hidden_layer1)\n",
    "    output_dur_layer = Dense(1, name = 'duration')(hidden_layer1)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=[output_dur_layer,output_dist_layer])\n",
    "\n",
    "    opt = optimizers.Adam(lr=0.001)\n",
    "    \n",
    "    LOSS_WEIGHTS = [1, 1]\n",
    "\n",
    "    model.compile(loss=['mse', 'mse'],\n",
    "                  optimizer=opt,\n",
    "                  metrics=[mape, mae, mare],\n",
    "                  loss_weights=LOSS_WEIGHTS)\n",
    "    return model\n",
    "\n",
    "dist_dur_dnn_model = build_dist_dur_model()\n",
    "print(dist_dur_dnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time stamp: 1554915233.296323\n",
      "WARNING:tensorflow:From C:\\Users\\Arthur\\Miniconda3\\envs\\general\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 6806066 samples, validate on 1944590 samples\n",
      "Epoch 1/100\n",
      "6806066/6806066 [==============================] - 39s 6us/step - loss: 0.0027 - duration_loss: 0.0023 - distance_loss: 4.6126e-04 - duration_mape: 37.6894 - duration_mae: 0.0317 - duration_mare: 26.1405 - distance_mape: 24.4263 - distance_mae: 0.0109 - distance_mare: 14.4701 - val_loss: 0.0023 - val_duration_loss: 0.0020 - val_distance_loss: 3.3190e-04 - val_duration_mape: 30.2751 - val_duration_mae: 0.0284 - val_duration_mare: 23.3878 - val_distance_mape: 16.6947 - val_distance_mae: 0.0090 - val_distance_mare: 11.9320\n",
      "Epoch 2/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0023 - duration_loss: 0.0019 - distance_loss: 3.2460e-04 - duration_mape: 33.0732 - duration_mae: 0.0289 - duration_mare: 23.8192 - distance_mape: 19.3588 - distance_mae: 0.0094 - distance_mare: 12.4568 - val_loss: 0.0022 - val_duration_loss: 0.0019 - val_distance_loss: 3.2952e-04 - val_duration_mape: 31.9506 - val_duration_mae: 0.0282 - val_duration_mare: 23.2427 - val_distance_mape: 25.4133 - val_distance_mae: 0.0105 - val_distance_mare: 13.9519\n",
      "Epoch 3/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0022 - duration_loss: 0.0019 - distance_loss: 3.1306e-04 - duration_mape: 31.9547 - duration_mae: 0.0282 - duration_mare: 23.2702 - distance_mape: 18.2250 - distance_mae: 0.0091 - distance_mare: 12.1112 - val_loss: 0.0022 - val_duration_loss: 0.0018 - val_distance_loss: 3.2064e-04 - val_duration_mape: 32.6033 - val_duration_mae: 0.0284 - val_duration_mare: 23.4155 - val_distance_mape: 23.2236 - val_distance_mae: 0.0103 - val_distance_mare: 13.6472\n",
      "Epoch 4/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0021 - duration_loss: 0.0018 - distance_loss: 3.0654e-04 - duration_mape: 31.3216 - duration_mae: 0.0278 - duration_mare: 22.9509 - distance_mape: 18.0023 - distance_mae: 0.0090 - distance_mare: 11.8683 - val_loss: 0.0021 - val_duration_loss: 0.0018 - val_distance_loss: 2.9573e-04 - val_duration_mape: 33.5585 - val_duration_mae: 0.0287 - val_duration_mare: 23.6480 - val_distance_mape: 17.9696 - val_distance_mae: 0.0089 - val_distance_mare: 11.7507\n",
      "Epoch 5/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0021 - duration_loss: 0.0018 - distance_loss: 3.0148e-04 - duration_mape: 30.8727 - duration_mae: 0.0276 - duration_mare: 22.7248 - distance_mape: 17.9723 - distance_mae: 0.0088 - distance_mare: 11.6903 - val_loss: 0.0021 - val_duration_loss: 0.0018 - val_distance_loss: 2.8906e-04 - val_duration_mape: 34.1316 - val_duration_mae: 0.0284 - val_duration_mare: 23.3753 - val_distance_mape: 18.0390 - val_distance_mae: 0.0085 - val_distance_mare: 11.3039\n",
      "Epoch 6/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0021 - duration_loss: 0.0018 - distance_loss: 2.9721e-04 - duration_mape: 30.5790 - duration_mae: 0.0274 - duration_mare: 22.5652 - distance_mape: 17.8189 - distance_mae: 0.0087 - distance_mare: 11.5616 - val_loss: 0.0021 - val_duration_loss: 0.0018 - val_distance_loss: 2.8990e-04 - val_duration_mape: 26.9394 - val_duration_mae: 0.0266 - val_duration_mare: 21.8984 - val_distance_mape: 15.7097 - val_distance_mae: 0.0082 - val_distance_mare: 10.8602\n",
      "Epoch 7/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0021 - duration_loss: 0.0018 - distance_loss: 2.9401e-04 - duration_mape: 30.3721 - duration_mae: 0.0272 - duration_mare: 22.4487 - distance_mape: 17.6449 - distance_mae: 0.0087 - distance_mare: 11.4578 - val_loss: 0.0020 - val_duration_loss: 0.0018 - val_distance_loss: 2.8775e-04 - val_duration_mape: 27.8944 - val_duration_mae: 0.0264 - val_duration_mare: 21.7789 - val_distance_mape: 15.5686 - val_distance_mae: 0.0082 - val_distance_mare: 10.9121\n",
      "Epoch 8/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0020 - duration_loss: 0.0018 - distance_loss: 2.9066e-04 - duration_mape: 30.1576 - duration_mae: 0.0271 - duration_mare: 22.3371 - distance_mape: 17.2992 - distance_mae: 0.0085 - distance_mare: 11.3207 - val_loss: 0.0021 - val_duration_loss: 0.0018 - val_distance_loss: 2.8377e-04 - val_duration_mape: 33.6021 - val_duration_mae: 0.0283 - val_duration_mare: 23.3127 - val_distance_mape: 16.7836 - val_distance_mae: 0.0085 - val_distance_mare: 11.2807\n",
      "Epoch 9/100\n",
      "6806066/6806066 [==============================] - 39s 6us/step - loss: 0.0020 - duration_loss: 0.0017 - distance_loss: 2.8738e-04 - duration_mape: 29.9766 - duration_mae: 0.0270 - duration_mare: 22.2358 - distance_mape: 16.9617 - distance_mae: 0.0085 - distance_mare: 11.2027 - val_loss: 0.0020 - val_duration_loss: 0.0017 - val_distance_loss: 2.8169e-04 - val_duration_mape: 30.6626 - val_duration_mae: 0.0273 - val_duration_mare: 22.5099 - val_distance_mape: 18.2906 - val_distance_mae: 0.0087 - val_distance_mare: 11.4799\n",
      "Epoch 10/100\n",
      "6806066/6806066 [==============================] - 39s 6us/step - loss: 0.0020 - duration_loss: 0.0017 - distance_loss: 2.8479e-04 - duration_mape: 29.8069 - duration_mae: 0.0269 - duration_mare: 22.1456 - distance_mape: 16.7070 - distance_mae: 0.0084 - distance_mare: 11.0945 - val_loss: 0.0020 - val_duration_loss: 0.0017 - val_distance_loss: 2.7883e-04 - val_duration_mape: 31.3849 - val_duration_mae: 0.0274 - val_duration_mare: 22.5839 - val_distance_mape: 17.7152 - val_distance_mae: 0.0086 - val_distance_mare: 11.4199\n",
      "Epoch 11/100\n",
      "6806066/6806066 [==============================] - 39s 6us/step - loss: 0.0020 - duration_loss: 0.0017 - distance_loss: 2.8322e-04 - duration_mape: 29.6985 - duration_mae: 0.0268 - duration_mare: 22.0814 - distance_mape: 16.6136 - distance_mae: 0.0083 - distance_mare: 11.0438 - val_loss: 0.0020 - val_duration_loss: 0.0017 - val_distance_loss: 2.7965e-04 - val_duration_mape: 30.7555 - val_duration_mae: 0.0270 - val_duration_mare: 22.2643 - val_distance_mape: 16.2838 - val_distance_mae: 0.0083 - val_distance_mare: 11.0487\n",
      "Epoch 12/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0020 - duration_loss: 0.0017 - distance_loss: 2.8124e-04 - duration_mape: 29.6040 - duration_mae: 0.0267 - duration_mare: 22.0280 - distance_mape: 16.4087 - distance_mae: 0.0083 - distance_mare: 10.9654 - val_loss: 0.0020 - val_duration_loss: 0.0017 - val_distance_loss: 2.7391e-04 - val_duration_mape: 31.1559 - val_duration_mae: 0.0270 - val_duration_mare: 22.2637 - val_distance_mape: 18.4240 - val_distance_mae: 0.0086 - val_distance_mare: 11.3297\n",
      "Epoch 13/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0020 - duration_loss: 0.0017 - distance_loss: 2.7989e-04 - duration_mape: 29.5042 - duration_mae: 0.0267 - duration_mare: 21.9734 - distance_mape: 16.3122 - distance_mae: 0.0082 - distance_mare: 10.9119 - val_loss: 0.0020 - val_duration_loss: 0.0017 - val_distance_loss: 2.7710e-04 - val_duration_mape: 30.5607 - val_duration_mae: 0.0270 - val_duration_mare: 22.2637 - val_distance_mape: 16.3225 - val_distance_mae: 0.0083 - val_distance_mare: 11.0020\n",
      "Epoch 14/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0020 - duration_loss: 0.0017 - distance_loss: 2.7832e-04 - duration_mape: 29.4187 - duration_mae: 0.0266 - duration_mare: 21.9241 - distance_mape: 16.2137 - distance_mae: 0.0082 - distance_mare: 10.8512 - val_loss: 0.0020 - val_duration_loss: 0.0017 - val_distance_loss: 2.7538e-04 - val_duration_mape: 27.3091 - val_duration_mae: 0.0262 - val_duration_mare: 21.5573 - val_distance_mape: 13.8559 - val_distance_mae: 0.0078 - val_distance_mare: 10.3840\n",
      "Epoch 15/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0020 - duration_loss: 0.0017 - distance_loss: 2.7699e-04 - duration_mape: 29.3403 - duration_mae: 0.0265 - duration_mare: 21.8832 - distance_mape: 16.1155 - distance_mae: 0.0082 - distance_mare: 10.8154 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.6982e-04 - val_duration_mape: 28.9821 - val_duration_mae: 0.0263 - val_duration_mare: 21.7118 - val_distance_mape: 14.7776 - val_distance_mae: 0.0078 - val_distance_mare: 10.3582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0020 - duration_loss: 0.0017 - distance_loss: 2.7581e-04 - duration_mape: 29.2425 - duration_mae: 0.0265 - duration_mare: 21.8314 - distance_mape: 15.9724 - distance_mae: 0.0081 - distance_mare: 10.7641 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.7102e-04 - val_duration_mape: 28.2805 - val_duration_mae: 0.0261 - val_duration_mare: 21.4939 - val_distance_mape: 13.9064 - val_distance_mae: 0.0078 - val_distance_mare: 10.2690\n",
      "Epoch 17/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0020 - duration_loss: 0.0017 - distance_loss: 2.7496e-04 - duration_mape: 29.2145 - duration_mae: 0.0265 - duration_mare: 21.8040 - distance_mape: 15.9401 - distance_mae: 0.0081 - distance_mare: 10.7415 - val_loss: 0.0020 - val_duration_loss: 0.0017 - val_distance_loss: 2.6996e-04 - val_duration_mape: 28.9494 - val_duration_mae: 0.0263 - val_duration_mare: 21.6606 - val_distance_mape: 16.1047 - val_distance_mae: 0.0081 - val_distance_mare: 10.7218\n",
      "Epoch 18/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0020 - duration_loss: 0.0017 - distance_loss: 2.7431e-04 - duration_mape: 29.1662 - duration_mae: 0.0264 - duration_mare: 21.7807 - distance_mape: 15.9042 - distance_mae: 0.0081 - distance_mare: 10.7190 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.6404e-04 - val_duration_mape: 29.2229 - val_duration_mae: 0.0263 - val_duration_mare: 21.6760 - val_distance_mape: 15.2523 - val_distance_mae: 0.0079 - val_distance_mare: 10.4235\n",
      "Epoch 19/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0020 - duration_loss: 0.0017 - distance_loss: 2.7318e-04 - duration_mape: 29.0531 - duration_mae: 0.0264 - duration_mare: 21.7288 - distance_mape: 15.8322 - distance_mae: 0.0081 - distance_mare: 10.6712 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.6894e-04 - val_duration_mape: 28.7507 - val_duration_mae: 0.0263 - val_duration_mare: 21.6582 - val_distance_mape: 17.1809 - val_distance_mae: 0.0083 - val_distance_mare: 10.9979\n",
      "Epoch 20/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0017 - distance_loss: 2.7263e-04 - duration_mape: 29.0310 - duration_mae: 0.0263 - duration_mare: 21.7099 - distance_mape: 15.8038 - distance_mae: 0.0080 - distance_mare: 10.6467 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.6546e-04 - val_duration_mape: 27.5887 - val_duration_mae: 0.0258 - val_duration_mare: 21.2697 - val_distance_mape: 17.3782 - val_distance_mae: 0.0083 - val_distance_mare: 10.9724\n",
      "Epoch 21/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0017 - distance_loss: 2.7183e-04 - duration_mape: 28.9526 - duration_mae: 0.0263 - duration_mare: 21.6872 - distance_mape: 15.7368 - distance_mae: 0.0080 - distance_mare: 10.6203 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.6277e-04 - val_duration_mape: 27.5631 - val_duration_mae: 0.0258 - val_duration_mare: 21.2841 - val_distance_mape: 15.0088 - val_distance_mae: 0.0079 - val_distance_mare: 10.4181\n",
      "Epoch 22/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0017 - distance_loss: 2.7116e-04 - duration_mape: 28.9397 - duration_mae: 0.0263 - duration_mare: 21.6685 - distance_mape: 15.7094 - distance_mae: 0.0080 - distance_mare: 10.6005 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.6308e-04 - val_duration_mape: 28.4043 - val_duration_mae: 0.0262 - val_duration_mare: 21.5753 - val_distance_mape: 13.8954 - val_distance_mae: 0.0077 - val_distance_mare: 10.1889\n",
      "Epoch 23/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0017 - distance_loss: 2.7032e-04 - duration_mape: 28.8668 - duration_mae: 0.0263 - duration_mare: 21.6402 - distance_mape: 15.7259 - distance_mae: 0.0080 - distance_mare: 10.5739 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.6154e-04 - val_duration_mape: 28.4800 - val_duration_mae: 0.0260 - val_duration_mare: 21.4381 - val_distance_mape: 14.1867 - val_distance_mae: 0.0076 - val_distance_mare: 10.0452\n",
      "Epoch 24/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0017 - distance_loss: 2.6956e-04 - duration_mape: 28.8268 - duration_mae: 0.0262 - duration_mare: 21.6176 - distance_mape: 15.6726 - distance_mae: 0.0080 - distance_mare: 10.5399 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.7014e-04 - val_duration_mape: 30.7360 - val_duration_mae: 0.0268 - val_duration_mare: 22.0827 - val_distance_mape: 15.5125 - val_distance_mae: 0.0081 - val_distance_mare: 10.7121\n",
      "Epoch 25/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0017 - distance_loss: 2.6928e-04 - duration_mape: 28.7833 - duration_mae: 0.0262 - duration_mare: 21.5918 - distance_mape: 15.6985 - distance_mae: 0.0080 - distance_mare: 10.5286 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.6354e-04 - val_duration_mape: 29.8176 - val_duration_mae: 0.0266 - val_duration_mare: 21.9459 - val_distance_mape: 15.0541 - val_distance_mae: 0.0079 - val_distance_mare: 10.4227\n",
      "Epoch 26/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0017 - distance_loss: 2.6853e-04 - duration_mape: 28.7322 - duration_mae: 0.0262 - duration_mare: 21.5684 - distance_mape: 15.6344 - distance_mae: 0.0079 - distance_mare: 10.4964 - val_loss: 0.0020 - val_duration_loss: 0.0017 - val_distance_loss: 2.6489e-04 - val_duration_mape: 25.4369 - val_duration_mae: 0.0256 - val_duration_mare: 21.0544 - val_distance_mape: 15.7117 - val_distance_mae: 0.0079 - val_distance_mare: 10.4977\n",
      "Epoch 27/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0017 - distance_loss: 2.6810e-04 - duration_mape: 28.7012 - duration_mae: 0.0262 - duration_mare: 21.5579 - distance_mape: 15.6557 - distance_mae: 0.0079 - distance_mare: 10.4929 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.6206e-04 - val_duration_mape: 26.5179 - val_duration_mae: 0.0256 - val_duration_mare: 21.0616 - val_distance_mape: 16.4264 - val_distance_mae: 0.0081 - val_distance_mare: 10.7905\n",
      "Epoch 28/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0017 - distance_loss: 2.6749e-04 - duration_mape: 28.6828 - duration_mae: 0.0261 - duration_mare: 21.5428 - distance_mape: 15.6246 - distance_mae: 0.0079 - distance_mare: 10.4723 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.6051e-04 - val_duration_mape: 29.0564 - val_duration_mae: 0.0260 - val_duration_mare: 21.4224 - val_distance_mape: 16.7986 - val_distance_mae: 0.0080 - val_distance_mare: 10.6000\n",
      "Epoch 29/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0017 - distance_loss: 2.6708e-04 - duration_mape: 28.6720 - duration_mae: 0.0261 - duration_mare: 21.5328 - distance_mape: 15.6113 - distance_mae: 0.0079 - distance_mare: 10.4597 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.6349e-04 - val_duration_mape: 27.1487 - val_duration_mae: 0.0256 - val_duration_mare: 21.1124 - val_distance_mape: 14.0255 - val_distance_mae: 0.0077 - val_distance_mare: 10.1894\n",
      "Epoch 30/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0017 - distance_loss: 2.6678e-04 - duration_mape: 28.6395 - duration_mae: 0.0261 - duration_mare: 21.5144 - distance_mape: 15.5841 - distance_mae: 0.0079 - distance_mare: 10.4472 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.6093e-04 - val_duration_mape: 28.5091 - val_duration_mae: 0.0260 - val_duration_mare: 21.4393 - val_distance_mape: 15.0587 - val_distance_mae: 0.0078 - val_distance_mare: 10.3508\n",
      "Epoch 31/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0017 - distance_loss: 2.6626e-04 - duration_mape: 28.6288 - duration_mae: 0.0261 - duration_mare: 21.5033 - distance_mape: 15.5479 - distance_mae: 0.0079 - distance_mare: 10.4329 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.6434e-04 - val_duration_mape: 27.5166 - val_duration_mae: 0.0257 - val_duration_mare: 21.2062 - val_distance_mape: 16.2052 - val_distance_mae: 0.0079 - val_distance_mare: 10.5227\n",
      "Epoch 32/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6615e-04 - duration_mape: 28.5789 - duration_mae: 0.0261 - duration_mare: 21.4840 - distance_mape: 15.5435 - distance_mae: 0.0079 - distance_mare: 10.4244 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.6882e-04 - val_duration_mape: 27.1646 - val_duration_mae: 0.0259 - val_duration_mare: 21.3215 - val_distance_mape: 14.2239 - val_distance_mae: 0.0078 - val_distance_mare: 10.3204\n",
      "Epoch 33/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6595e-04 - duration_mape: 28.5609 - duration_mae: 0.0260 - duration_mare: 21.4715 - distance_mape: 15.5303 - distance_mae: 0.0079 - distance_mare: 10.4221 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.5767e-04 - val_duration_mape: 27.8063 - val_duration_mae: 0.0259 - val_duration_mare: 21.3481 - val_distance_mape: 14.4779 - val_distance_mae: 0.0077 - val_distance_mare: 10.2444\n",
      "Epoch 34/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6567e-04 - duration_mape: 28.5551 - duration_mae: 0.0260 - duration_mare: 21.4613 - distance_mape: 15.5267 - distance_mae: 0.0079 - distance_mare: 10.4114 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.6131e-04 - val_duration_mape: 26.1721 - val_duration_mae: 0.0254 - val_duration_mare: 20.9113 - val_distance_mape: 14.1450 - val_distance_mae: 0.0076 - val_distance_mare: 10.0574\n",
      "Epoch 35/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6532e-04 - duration_mape: 28.5205 - duration_mae: 0.0260 - duration_mare: 21.4466 - distance_mape: 15.5247 - distance_mae: 0.0079 - distance_mare: 10.4030 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5761e-04 - val_duration_mape: 27.4811 - val_duration_mae: 0.0256 - val_duration_mare: 21.0911 - val_distance_mape: 14.2236 - val_distance_mae: 0.0076 - val_distance_mare: 10.0616\n",
      "Epoch 36/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6521e-04 - duration_mape: 28.5187 - duration_mae: 0.0260 - duration_mare: 21.4479 - distance_mape: 15.5042 - distance_mae: 0.0079 - distance_mare: 10.4013 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.6334e-04 - val_duration_mape: 26.3769 - val_duration_mae: 0.0255 - val_duration_mare: 20.9802 - val_distance_mape: 15.1046 - val_distance_mae: 0.0080 - val_distance_mare: 10.5761\n",
      "Epoch 37/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6489e-04 - duration_mape: 28.4894 - duration_mae: 0.0260 - duration_mare: 21.4342 - distance_mape: 15.4270 - distance_mae: 0.0079 - distance_mare: 10.3962 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.8112e-04 - val_duration_mape: 28.7432 - val_duration_mae: 0.0259 - val_duration_mare: 21.3678 - val_distance_mape: 13.6271 - val_distance_mae: 0.0079 - val_distance_mare: 10.4621\n",
      "Epoch 38/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6489e-04 - duration_mape: 28.5050 - duration_mae: 0.0260 - duration_mare: 21.4311 - distance_mape: 15.5121 - distance_mae: 0.0078 - distance_mare: 10.3942 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.6495e-04 - val_duration_mape: 28.2593 - val_duration_mae: 0.0259 - val_duration_mare: 21.3142 - val_distance_mape: 16.5163 - val_distance_mae: 0.0082 - val_distance_mare: 10.8130\n",
      "Epoch 39/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6444e-04 - duration_mape: 28.4428 - duration_mae: 0.0260 - duration_mare: 21.4104 - distance_mape: 15.4631 - distance_mae: 0.0078 - distance_mare: 10.3794 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5797e-04 - val_duration_mape: 28.1130 - val_duration_mae: 0.0259 - val_duration_mare: 21.3654 - val_distance_mape: 15.1486 - val_distance_mae: 0.0079 - val_distance_mare: 10.4958\n",
      "Epoch 40/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6419e-04 - duration_mape: 28.4203 - duration_mae: 0.0260 - duration_mare: 21.4019 - distance_mape: 15.3106 - distance_mae: 0.0078 - distance_mare: 10.3682 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5822e-04 - val_duration_mape: 29.3539 - val_duration_mae: 0.0262 - val_duration_mare: 21.6199 - val_distance_mape: 15.4913 - val_distance_mae: 0.0079 - val_distance_mare: 10.4797\n",
      "Epoch 41/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6389e-04 - duration_mape: 28.4194 - duration_mae: 0.0260 - duration_mare: 21.3980 - distance_mape: 15.2800 - distance_mae: 0.0078 - distance_mare: 10.3695 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5763e-04 - val_duration_mape: 26.6646 - val_duration_mae: 0.0256 - val_duration_mare: 21.0697 - val_distance_mape: 16.1786 - val_distance_mae: 0.0079 - val_distance_mare: 10.4674\n",
      "Epoch 42/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6392e-04 - duration_mape: 28.3771 - duration_mae: 0.0259 - duration_mare: 21.3849 - distance_mape: 15.2671 - distance_mae: 0.0078 - distance_mare: 10.3716 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5943e-04 - val_duration_mape: 28.4474 - val_duration_mae: 0.0260 - val_duration_mare: 21.4609 - val_distance_mape: 16.1138 - val_distance_mae: 0.0080 - val_distance_mare: 10.5502\n",
      "Epoch 43/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6361e-04 - duration_mape: 28.3806 - duration_mae: 0.0259 - duration_mare: 21.3805 - distance_mape: 15.2793 - distance_mae: 0.0078 - distance_mare: 10.3608 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.6144e-04 - val_duration_mape: 29.6107 - val_duration_mae: 0.0265 - val_duration_mare: 21.8266 - val_distance_mape: 17.7204 - val_distance_mae: 0.0083 - val_distance_mare: 11.0268\n",
      "Epoch 44/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6332e-04 - duration_mape: 28.3587 - duration_mae: 0.0259 - duration_mare: 21.3720 - distance_mape: 15.2190 - distance_mae: 0.0078 - distance_mare: 10.3532 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5672e-04 - val_duration_mape: 26.9269 - val_duration_mae: 0.0257 - val_duration_mare: 21.1627 - val_distance_mape: 14.4457 - val_distance_mae: 0.0076 - val_distance_mare: 10.0170\n",
      "Epoch 45/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6304e-04 - duration_mape: 28.3340 - duration_mae: 0.0259 - duration_mare: 21.3592 - distance_mape: 15.2480 - distance_mae: 0.0078 - distance_mare: 10.3519 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.7466e-04 - val_duration_mape: 26.0373 - val_duration_mae: 0.0254 - val_duration_mare: 20.9575 - val_distance_mape: 14.9599 - val_distance_mae: 0.0080 - val_distance_mare: 10.6377\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6283e-04 - duration_mape: 28.3133 - duration_mae: 0.0259 - duration_mare: 21.3520 - distance_mape: 15.1930 - distance_mae: 0.0078 - distance_mare: 10.3386 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5687e-04 - val_duration_mape: 28.0752 - val_duration_mae: 0.0258 - val_duration_mare: 21.2815 - val_distance_mape: 14.0740 - val_distance_mae: 0.0075 - val_distance_mare: 9.9919\n",
      "Epoch 47/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6220e-04 - duration_mape: 28.2810 - duration_mae: 0.0259 - duration_mare: 21.3370 - distance_mape: 15.1330 - distance_mae: 0.0078 - distance_mare: 10.3133 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5825e-04 - val_duration_mape: 27.2826 - val_duration_mae: 0.0256 - val_duration_mare: 21.1173 - val_distance_mape: 15.5052 - val_distance_mae: 0.0078 - val_distance_mare: 10.3222\n",
      "Epoch 48/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6232e-04 - duration_mape: 28.2914 - duration_mae: 0.0259 - duration_mare: 21.3419 - distance_mape: 15.1793 - distance_mae: 0.0078 - distance_mare: 10.3305 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5574e-04 - val_duration_mape: 27.1931 - val_duration_mae: 0.0257 - val_duration_mare: 21.1717 - val_distance_mape: 13.6115 - val_distance_mae: 0.0076 - val_distance_mare: 10.0635\n",
      "Epoch 49/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6219e-04 - duration_mape: 28.2892 - duration_mae: 0.0259 - duration_mare: 21.3358 - distance_mape: 15.2227 - distance_mae: 0.0078 - distance_mare: 10.3296 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5953e-04 - val_duration_mape: 30.4986 - val_duration_mae: 0.0266 - val_duration_mare: 21.9572 - val_distance_mape: 17.6476 - val_distance_mae: 0.0083 - val_distance_mare: 11.0179\n",
      "Epoch 50/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6178e-04 - duration_mape: 28.2371 - duration_mae: 0.0259 - duration_mare: 21.3182 - distance_mape: 15.1444 - distance_mae: 0.0078 - distance_mare: 10.3121 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.6030e-04 - val_duration_mape: 27.1332 - val_duration_mae: 0.0257 - val_duration_mare: 21.1983 - val_distance_mape: 13.4315 - val_distance_mae: 0.0075 - val_distance_mare: 9.9400\n",
      "Epoch 51/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6183e-04 - duration_mape: 28.2944 - duration_mae: 0.0259 - duration_mare: 21.3315 - distance_mape: 15.2345 - distance_mae: 0.0078 - distance_mare: 10.3337 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.6166e-04 - val_duration_mape: 29.6580 - val_duration_mae: 0.0264 - val_duration_mare: 21.7691 - val_distance_mape: 17.8127 - val_distance_mae: 0.0084 - val_distance_mare: 11.1354\n",
      "Epoch 52/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6163e-04 - duration_mape: 28.2567 - duration_mae: 0.0259 - duration_mare: 21.3203 - distance_mape: 15.2178 - distance_mae: 0.0078 - distance_mare: 10.3191 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5793e-04 - val_duration_mape: 28.6659 - val_duration_mae: 0.0258 - val_duration_mare: 21.2646 - val_distance_mape: 13.4197 - val_distance_mae: 0.0076 - val_distance_mare: 10.0014\n",
      "Epoch 53/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6143e-04 - duration_mape: 28.2158 - duration_mae: 0.0258 - duration_mare: 21.3058 - distance_mape: 15.1673 - distance_mae: 0.0078 - distance_mare: 10.3089 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.6037e-04 - val_duration_mape: 29.0103 - val_duration_mae: 0.0260 - val_duration_mare: 21.4475 - val_distance_mape: 16.4949 - val_distance_mae: 0.0081 - val_distance_mare: 10.7538\n",
      "Epoch 54/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6146e-04 - duration_mape: 28.2160 - duration_mae: 0.0258 - duration_mare: 21.3057 - distance_mape: 15.2132 - distance_mae: 0.0078 - distance_mare: 10.3170 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5428e-04 - val_duration_mape: 27.1148 - val_duration_mae: 0.0255 - val_duration_mare: 20.9902 - val_distance_mape: 15.5742 - val_distance_mae: 0.0078 - val_distance_mare: 10.3598\n",
      "Epoch 55/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6135e-04 - duration_mape: 28.2134 - duration_mae: 0.0258 - duration_mare: 21.2972 - distance_mape: 15.1767 - distance_mae: 0.0078 - distance_mare: 10.3091 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5646e-04 - val_duration_mape: 27.8633 - val_duration_mae: 0.0256 - val_duration_mare: 21.0844 - val_distance_mape: 13.4038 - val_distance_mae: 0.0074 - val_distance_mare: 9.8208\n",
      "Epoch 56/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6099e-04 - duration_mape: 28.1901 - duration_mae: 0.0258 - duration_mare: 21.2887 - distance_mape: 15.1908 - distance_mae: 0.0078 - distance_mare: 10.3042 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5352e-04 - val_duration_mape: 28.1668 - val_duration_mae: 0.0258 - val_duration_mare: 21.2298 - val_distance_mape: 15.6204 - val_distance_mae: 0.0077 - val_distance_mare: 10.1699\n",
      "Epoch 57/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6082e-04 - duration_mape: 28.1831 - duration_mae: 0.0258 - duration_mare: 21.2869 - distance_mape: 15.1793 - distance_mae: 0.0078 - distance_mare: 10.2950 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5534e-04 - val_duration_mape: 27.6087 - val_duration_mae: 0.0257 - val_duration_mare: 21.1361 - val_distance_mape: 16.4447 - val_distance_mae: 0.0080 - val_distance_mare: 10.5961\n",
      "Epoch 58/100\n",
      "6806066/6806066 [==============================] - 37s 5us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6056e-04 - duration_mape: 28.1760 - duration_mae: 0.0258 - duration_mare: 21.2787 - distance_mape: 15.1787 - distance_mae: 0.0078 - distance_mare: 10.2811 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5885e-04 - val_duration_mape: 28.6827 - val_duration_mae: 0.0262 - val_duration_mare: 21.5532 - val_distance_mape: 15.9465 - val_distance_mae: 0.0081 - val_distance_mare: 10.7025\n",
      "Epoch 59/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6058e-04 - duration_mape: 28.1820 - duration_mae: 0.0258 - duration_mare: 21.2801 - distance_mape: 15.2244 - distance_mae: 0.0078 - distance_mare: 10.2904 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5604e-04 - val_duration_mape: 27.8451 - val_duration_mae: 0.0257 - val_duration_mare: 21.1690 - val_distance_mape: 15.3635 - val_distance_mae: 0.0077 - val_distance_mare: 10.2099\n",
      "Epoch 60/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6033e-04 - duration_mape: 28.1435 - duration_mae: 0.0258 - duration_mare: 21.2588 - distance_mape: 15.1675 - distance_mae: 0.0078 - distance_mare: 10.2816 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5992e-04 - val_duration_mape: 28.4599 - val_duration_mae: 0.0261 - val_duration_mare: 21.5206 - val_distance_mape: 16.0169 - val_distance_mae: 0.0080 - val_distance_mare: 10.5869\n",
      "Epoch 61/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6017e-04 - duration_mape: 28.1396 - duration_mae: 0.0258 - duration_mare: 21.2597 - distance_mape: 15.1574 - distance_mae: 0.0078 - distance_mare: 10.2729 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.6201e-04 - val_duration_mape: 32.7892 - val_duration_mae: 0.0272 - val_duration_mare: 22.3892 - val_distance_mape: 20.5351 - val_distance_mae: 0.0087 - val_distance_mare: 11.5030\n",
      "Epoch 62/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6038e-04 - duration_mape: 28.1536 - duration_mae: 0.0258 - duration_mare: 21.2628 - distance_mape: 15.1900 - distance_mae: 0.0078 - distance_mare: 10.2904 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5868e-04 - val_duration_mape: 28.8163 - val_duration_mae: 0.0260 - val_duration_mare: 21.4529 - val_distance_mape: 16.9698 - val_distance_mae: 0.0081 - val_distance_mare: 10.7149\n",
      "Epoch 63/100\n",
      "6806066/6806066 [==============================] - 40s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.6005e-04 - duration_mape: 28.1383 - duration_mae: 0.0258 - duration_mare: 21.2597 - distance_mape: 15.1929 - distance_mae: 0.0078 - distance_mare: 10.2833 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5519e-04 - val_duration_mape: 26.8516 - val_duration_mae: 0.0254 - val_duration_mare: 20.9590 - val_distance_mape: 14.5686 - val_distance_mae: 0.0077 - val_distance_mare: 10.2434\n",
      "Epoch 64/100\n",
      "6806066/6806066 [==============================] - 39s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5982e-04 - duration_mape: 28.1039 - duration_mae: 0.0258 - duration_mare: 21.2481 - distance_mape: 15.1698 - distance_mae: 0.0078 - distance_mare: 10.2720 - val_loss: 0.0019 - val_duration_loss: 0.0017 - val_distance_loss: 2.6212e-04 - val_duration_mape: 28.8591 - val_duration_mae: 0.0266 - val_duration_mare: 21.9025 - val_distance_mape: 16.8311 - val_distance_mae: 0.0082 - val_distance_mare: 10.8172\n",
      "Epoch 65/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5994e-04 - duration_mape: 28.1260 - duration_mae: 0.0258 - duration_mare: 21.2511 - distance_mape: 15.1791 - distance_mae: 0.0078 - distance_mare: 10.2797 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5406e-04 - val_duration_mape: 27.5086 - val_duration_mae: 0.0256 - val_duration_mare: 21.0823 - val_distance_mape: 14.9645 - val_distance_mae: 0.0077 - val_distance_mare: 10.2382\n",
      "Epoch 66/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5963e-04 - duration_mape: 28.0853 - duration_mae: 0.0258 - duration_mare: 21.2404 - distance_mape: 15.1459 - distance_mae: 0.0077 - distance_mare: 10.2560 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5838e-04 - val_duration_mape: 26.5233 - val_duration_mae: 0.0257 - val_duration_mare: 21.1826 - val_distance_mape: 13.9112 - val_distance_mae: 0.0078 - val_distance_mare: 10.3292\n",
      "Epoch 67/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5952e-04 - duration_mape: 28.0878 - duration_mae: 0.0258 - duration_mare: 21.2373 - distance_mape: 15.1655 - distance_mae: 0.0077 - distance_mare: 10.2631 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5973e-04 - val_duration_mape: 27.3560 - val_duration_mae: 0.0255 - val_duration_mare: 20.9754 - val_distance_mape: 13.4183 - val_distance_mae: 0.0073 - val_distance_mare: 9.7116\n",
      "Epoch 68/100\n",
      "6806066/6806066 [==============================] - 40s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5948e-04 - duration_mape: 28.0706 - duration_mae: 0.0258 - duration_mare: 21.2326 - distance_mape: 15.1267 - distance_mae: 0.0077 - distance_mare: 10.2554 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.6149e-04 - val_duration_mape: 29.1757 - val_duration_mae: 0.0263 - val_duration_mare: 21.6685 - val_distance_mape: 16.1576 - val_distance_mae: 0.0080 - val_distance_mare: 10.6094\n",
      "Epoch 69/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5940e-04 - duration_mape: 28.0655 - duration_mae: 0.0258 - duration_mare: 21.2266 - distance_mape: 15.1326 - distance_mae: 0.0077 - distance_mare: 10.2557 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5684e-04 - val_duration_mape: 27.6046 - val_duration_mae: 0.0258 - val_duration_mare: 21.2237 - val_distance_mape: 15.6835 - val_distance_mae: 0.0079 - val_distance_mare: 10.4339\n",
      "Epoch 70/100\n",
      "6806066/6806066 [==============================] - 37s 5us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5912e-04 - duration_mape: 28.0376 - duration_mae: 0.0257 - duration_mare: 21.2204 - distance_mape: 15.1142 - distance_mae: 0.0077 - distance_mare: 10.2447 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5347e-04 - val_duration_mape: 27.7090 - val_duration_mae: 0.0255 - val_duration_mare: 21.0517 - val_distance_mape: 13.9444 - val_distance_mae: 0.0074 - val_distance_mare: 9.7464\n",
      "Epoch 71/100\n",
      "6806066/6806066 [==============================] - 37s 5us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5908e-04 - duration_mape: 28.0505 - duration_mae: 0.0257 - duration_mare: 21.2205 - distance_mape: 15.1319 - distance_mae: 0.0077 - distance_mare: 10.2473 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5278e-04 - val_duration_mape: 27.4411 - val_duration_mae: 0.0258 - val_duration_mare: 21.2322 - val_distance_mape: 15.5845 - val_distance_mae: 0.0078 - val_distance_mare: 10.2724\n",
      "Epoch 72/100\n",
      "6806066/6806066 [==============================] - 37s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5901e-04 - duration_mape: 28.0436 - duration_mae: 0.0257 - duration_mare: 21.2218 - distance_mape: 15.1282 - distance_mae: 0.0077 - distance_mare: 10.2475 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5755e-04 - val_duration_mape: 29.9303 - val_duration_mae: 0.0265 - val_duration_mare: 21.7999 - val_distance_mape: 16.1296 - val_distance_mae: 0.0081 - val_distance_mare: 10.7925\n",
      "Epoch 73/100\n",
      "6806066/6806066 [==============================] - 37s 5us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5893e-04 - duration_mape: 28.0304 - duration_mae: 0.0257 - duration_mare: 21.2142 - distance_mape: 15.0969 - distance_mae: 0.0077 - distance_mare: 10.2356 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5527e-04 - val_duration_mape: 28.1764 - val_duration_mae: 0.0258 - val_duration_mare: 21.2380 - val_distance_mape: 14.4211 - val_distance_mae: 0.0077 - val_distance_mare: 10.2394\n",
      "Epoch 74/100\n",
      "6806066/6806066 [==============================] - 37s 5us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5914e-04 - duration_mape: 28.0239 - duration_mae: 0.0257 - duration_mare: 21.2090 - distance_mape: 15.1158 - distance_mae: 0.0077 - distance_mare: 10.2484 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5197e-04 - val_duration_mape: 28.9639 - val_duration_mae: 0.0261 - val_duration_mare: 21.4926 - val_distance_mape: 14.3455 - val_distance_mae: 0.0076 - val_distance_mare: 10.0991\n",
      "Epoch 75/100\n",
      "6806066/6806066 [==============================] - 40s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5884e-04 - duration_mape: 28.0299 - duration_mae: 0.0257 - duration_mare: 21.2097 - distance_mape: 15.1275 - distance_mae: 0.0077 - distance_mare: 10.2406 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5402e-04 - val_duration_mape: 27.4158 - val_duration_mae: 0.0253 - val_duration_mare: 20.8621 - val_distance_mape: 15.0562 - val_distance_mae: 0.0076 - val_distance_mare: 10.0311\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6806066/6806066 [==============================] - 42s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5879e-04 - duration_mape: 28.0257 - duration_mae: 0.0257 - duration_mare: 21.2082 - distance_mape: 15.1207 - distance_mae: 0.0077 - distance_mare: 10.2425 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5878e-04 - val_duration_mape: 28.6735 - val_duration_mae: 0.0259 - val_duration_mare: 21.3053 - val_distance_mape: 14.7423 - val_distance_mae: 0.0078 - val_distance_mare: 10.3570\n",
      "Epoch 77/100\n",
      "6806066/6806066 [==============================] - 41s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5886e-04 - duration_mape: 28.0106 - duration_mae: 0.0257 - duration_mare: 21.1991 - distance_mape: 15.1193 - distance_mae: 0.0077 - distance_mare: 10.2446 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5974e-04 - val_duration_mape: 28.4445 - val_duration_mae: 0.0259 - val_duration_mare: 21.3210 - val_distance_mape: 15.0004 - val_distance_mae: 0.0078 - val_distance_mare: 10.3015\n",
      "Epoch 78/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5848e-04 - duration_mape: 27.9865 - duration_mae: 0.0257 - duration_mare: 21.1945 - distance_mape: 15.0460 - distance_mae: 0.0077 - distance_mare: 10.2187 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5558e-04 - val_duration_mape: 29.3641 - val_duration_mae: 0.0265 - val_duration_mare: 21.8230 - val_distance_mape: 17.4253 - val_distance_mae: 0.0082 - val_distance_mare: 10.8266\n",
      "Epoch 79/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5856e-04 - duration_mape: 28.0168 - duration_mae: 0.0257 - duration_mare: 21.2001 - distance_mape: 15.1273 - distance_mae: 0.0077 - distance_mare: 10.2356 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.6181e-04 - val_duration_mape: 25.4837 - val_duration_mae: 0.0253 - val_duration_mare: 20.8562 - val_distance_mape: 14.7153 - val_distance_mae: 0.0080 - val_distance_mare: 10.5334\n",
      "Epoch 80/100\n",
      "6806066/6806066 [==============================] - 37s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5891e-04 - duration_mape: 27.9955 - duration_mae: 0.0257 - duration_mare: 21.1952 - distance_mape: 15.1514 - distance_mae: 0.0077 - distance_mare: 10.2426 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5252e-04 - val_duration_mape: 27.9910 - val_duration_mae: 0.0256 - val_duration_mare: 21.1156 - val_distance_mape: 15.4663 - val_distance_mae: 0.0078 - val_distance_mare: 10.3891\n",
      "Epoch 81/100\n",
      "6806066/6806066 [==============================] - 37s 5us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5867e-04 - duration_mape: 28.0131 - duration_mae: 0.0257 - duration_mare: 21.1971 - distance_mape: 15.1243 - distance_mae: 0.0077 - distance_mare: 10.2385 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5246e-04 - val_duration_mape: 27.1922 - val_duration_mae: 0.0255 - val_duration_mare: 20.9981 - val_distance_mape: 13.8056 - val_distance_mae: 0.0073 - val_distance_mare: 9.7156\n",
      "Epoch 82/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5840e-04 - duration_mape: 27.9748 - duration_mae: 0.0257 - duration_mare: 21.1794 - distance_mape: 15.0795 - distance_mae: 0.0077 - distance_mare: 10.2232 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5666e-04 - val_duration_mape: 31.7717 - val_duration_mae: 0.0270 - val_duration_mare: 22.2384 - val_distance_mape: 18.8909 - val_distance_mae: 0.0084 - val_distance_mare: 11.1770\n",
      "Epoch 83/100\n",
      "6806066/6806066 [==============================] - 39s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5842e-04 - duration_mape: 27.9732 - duration_mae: 0.0257 - duration_mare: 21.1790 - distance_mape: 15.1281 - distance_mae: 0.0077 - distance_mare: 10.2240 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5311e-04 - val_duration_mape: 28.0195 - val_duration_mae: 0.0257 - val_duration_mare: 21.1682 - val_distance_mape: 13.2041 - val_distance_mae: 0.0074 - val_distance_mare: 9.8062\n",
      "Epoch 84/100\n",
      "6806066/6806066 [==============================] - 39s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5823e-04 - duration_mape: 27.9560 - duration_mae: 0.0257 - duration_mare: 21.1781 - distance_mape: 15.0940 - distance_mae: 0.0077 - distance_mare: 10.2173 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.6167e-04 - val_duration_mape: 28.4741 - val_duration_mae: 0.0259 - val_duration_mare: 21.3290 - val_distance_mape: 15.6772 - val_distance_mae: 0.0079 - val_distance_mare: 10.4654\n",
      "Epoch 85/100\n",
      "6806066/6806066 [==============================] - 37s 5us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5823e-04 - duration_mape: 27.9381 - duration_mae: 0.0257 - duration_mare: 21.1711 - distance_mape: 15.0823 - distance_mae: 0.0077 - distance_mare: 10.2206 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.6608e-04 - val_duration_mape: 28.0027 - val_duration_mae: 0.0258 - val_duration_mare: 21.2663 - val_distance_mape: 19.4671 - val_distance_mae: 0.0089 - val_distance_mare: 11.7807\n",
      "Epoch 86/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5816e-04 - duration_mape: 27.9799 - duration_mae: 0.0257 - duration_mare: 21.1772 - distance_mape: 15.0475 - distance_mae: 0.0077 - distance_mare: 10.2119 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.4905e-04 - val_duration_mape: 27.8526 - val_duration_mae: 0.0256 - val_duration_mare: 21.1196 - val_distance_mape: 13.9244 - val_distance_mae: 0.0074 - val_distance_mare: 9.7363\n",
      "Epoch 87/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5802e-04 - duration_mape: 27.9652 - duration_mae: 0.0257 - duration_mare: 21.1682 - distance_mape: 15.0692 - distance_mae: 0.0077 - distance_mare: 10.2150 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5497e-04 - val_duration_mape: 27.6176 - val_duration_mae: 0.0257 - val_duration_mare: 21.1543 - val_distance_mape: 14.5633 - val_distance_mae: 0.0077 - val_distance_mare: 10.1783\n",
      "Epoch 88/100\n",
      "6806066/6806066 [==============================] - 39s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5812e-04 - duration_mape: 27.9372 - duration_mae: 0.0257 - duration_mare: 21.1607 - distance_mape: 15.1153 - distance_mae: 0.0077 - distance_mare: 10.2198 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5110e-04 - val_duration_mape: 28.6073 - val_duration_mae: 0.0259 - val_duration_mare: 21.3604 - val_distance_mape: 15.4047 - val_distance_mae: 0.0078 - val_distance_mare: 10.3045\n",
      "Epoch 89/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5766e-04 - duration_mape: 27.9359 - duration_mae: 0.0257 - duration_mare: 21.1611 - distance_mape: 15.0459 - distance_mae: 0.0077 - distance_mare: 10.1972 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5421e-04 - val_duration_mape: 28.5621 - val_duration_mae: 0.0259 - val_duration_mare: 21.3158 - val_distance_mape: 14.9277 - val_distance_mae: 0.0077 - val_distance_mare: 10.1609\n",
      "Epoch 90/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5798e-04 - duration_mape: 27.9412 - duration_mae: 0.0257 - duration_mare: 21.1587 - distance_mape: 15.0982 - distance_mae: 0.0077 - distance_mare: 10.2182 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5240e-04 - val_duration_mape: 27.2406 - val_duration_mae: 0.0254 - val_duration_mare: 20.9467 - val_distance_mape: 13.1373 - val_distance_mae: 0.0073 - val_distance_mare: 9.7095\n",
      "Epoch 91/100\n",
      "6806066/6806066 [==============================] - 37s 5us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5764e-04 - duration_mape: 27.9225 - duration_mae: 0.0257 - duration_mare: 21.1529 - distance_mape: 15.0470 - distance_mae: 0.0077 - distance_mare: 10.2001 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5136e-04 - val_duration_mape: 28.6920 - val_duration_mae: 0.0257 - val_duration_mare: 21.1949 - val_distance_mape: 13.1689 - val_distance_mae: 0.0073 - val_distance_mare: 9.6818\n",
      "Epoch 92/100\n",
      "6806066/6806066 [==============================] - 38s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5770e-04 - duration_mape: 27.9318 - duration_mae: 0.0257 - duration_mare: 21.1555 - distance_mape: 15.0534 - distance_mae: 0.0077 - distance_mare: 10.1996 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5259e-04 - val_duration_mape: 25.4509 - val_duration_mae: 0.0253 - val_duration_mare: 20.8392 - val_distance_mape: 12.8098 - val_distance_mae: 0.0074 - val_distance_mare: 9.7486\n",
      "Epoch 93/100\n",
      "6806066/6806066 [==============================] - 39s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5751e-04 - duration_mape: 27.9187 - duration_mae: 0.0257 - duration_mare: 21.1492 - distance_mape: 15.0344 - distance_mae: 0.0077 - distance_mare: 10.1909 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5499e-04 - val_duration_mape: 27.4677 - val_duration_mae: 0.0256 - val_duration_mare: 21.0673 - val_distance_mape: 14.7818 - val_distance_mae: 0.0077 - val_distance_mare: 10.2521\n",
      "Epoch 94/100\n",
      "6806066/6806066 [==============================] - 40s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5758e-04 - duration_mape: 27.8988 - duration_mae: 0.0256 - duration_mare: 21.1412 - distance_mape: 14.9949 - distance_mae: 0.0077 - distance_mare: 10.1954 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5334e-04 - val_duration_mape: 26.1581 - val_duration_mae: 0.0252 - val_duration_mare: 20.7935 - val_distance_mape: 13.3814 - val_distance_mae: 0.0074 - val_distance_mare: 9.7556\n",
      "Epoch 95/100\n",
      "6806066/6806066 [==============================] - 39s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5775e-04 - duration_mape: 27.9261 - duration_mae: 0.0257 - duration_mare: 21.1451 - distance_mape: 15.0652 - distance_mae: 0.0077 - distance_mare: 10.2041 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5199e-04 - val_duration_mape: 28.8924 - val_duration_mae: 0.0259 - val_duration_mare: 21.3025 - val_distance_mape: 16.2383 - val_distance_mae: 0.0078 - val_distance_mare: 10.3765\n",
      "Epoch 96/100\n",
      "6806066/6806066 [==============================] - 39s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5723e-04 - duration_mape: 27.8763 - duration_mae: 0.0256 - duration_mare: 21.1337 - distance_mape: 14.9855 - distance_mae: 0.0077 - distance_mare: 10.1767 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5137e-04 - val_duration_mape: 27.4574 - val_duration_mae: 0.0255 - val_duration_mare: 21.0170 - val_distance_mape: 14.4887 - val_distance_mae: 0.0075 - val_distance_mare: 9.9173\n",
      "Epoch 97/100\n",
      "6806066/6806066 [==============================] - 40s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5746e-04 - duration_mape: 27.9047 - duration_mae: 0.0256 - duration_mare: 21.1404 - distance_mape: 15.0669 - distance_mae: 0.0077 - distance_mare: 10.1993 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.4947e-04 - val_duration_mape: 29.1578 - val_duration_mae: 0.0258 - val_duration_mare: 21.2852 - val_distance_mape: 14.2366 - val_distance_mae: 0.0075 - val_distance_mare: 9.9014\n",
      "Epoch 98/100\n",
      "6806066/6806066 [==============================] - 39s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5739e-04 - duration_mape: 27.8956 - duration_mae: 0.0256 - duration_mare: 21.1337 - distance_mape: 15.0367 - distance_mae: 0.0077 - distance_mare: 10.1920 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5505e-04 - val_duration_mape: 28.9023 - val_duration_mae: 0.0258 - val_duration_mare: 21.2859 - val_distance_mape: 16.3348 - val_distance_mae: 0.0079 - val_distance_mare: 10.4622\n",
      "Epoch 99/100\n",
      "6806066/6806066 [==============================] - 40s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5713e-04 - duration_mape: 27.8809 - duration_mae: 0.0256 - duration_mare: 21.1278 - distance_mape: 15.0283 - distance_mae: 0.0077 - distance_mare: 10.1861 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5564e-04 - val_duration_mape: 26.0582 - val_duration_mae: 0.0252 - val_duration_mare: 20.7855 - val_distance_mape: 13.0214 - val_distance_mae: 0.0074 - val_distance_mare: 9.7337\n",
      "Epoch 100/100\n",
      "6806066/6806066 [==============================] - 40s 6us/step - loss: 0.0019 - duration_loss: 0.0016 - distance_loss: 2.5728e-04 - duration_mape: 27.8750 - duration_mae: 0.0256 - duration_mare: 21.1261 - distance_mape: 15.0106 - distance_mae: 0.0077 - distance_mare: 10.1851 - val_loss: 0.0019 - val_duration_loss: 0.0016 - val_distance_loss: 2.5266e-04 - val_duration_mape: 27.7014 - val_duration_mae: 0.0256 - val_duration_mare: 21.0556 - val_distance_mape: 13.6759 - val_distance_mae: 0.0075 - val_distance_mare: 9.8653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19621500eb8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 1024\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "time_stamp = time()\n",
    "print('Time stamp:', time_stamp)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='tb_logs/dur_dist_dnn_{}'.format(time_stamp))\n",
    "\n",
    "COLS = [0,1,2,3,5,6,7,8]\n",
    "\n",
    "dist_dur_dnn_model.fit(x=train_input[:,COLS],\n",
    "                       y=[train_output[:,0], train_output[:,1]],\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       epochs=NUM_EPOCHS,\n",
    "                       validation_data=(valid_input[:,COLS], [valid_output[:,0], valid_output[:,1]]),\n",
    "                       callbacks=[tensorboard])\n",
    "\n",
    "# model.fit(x=train_input,\n",
    "#           y=train_output[:,0],\n",
    "#           batch_size=BATCH_SIZE,\n",
    "#           epochs=NUM_EPOCHS,\n",
    "#           validation_data=(valid_input,valid_output[:,0]),\n",
    "#           callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to disk.\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model_json = dist_dur_dnn_model.to_json()\n",
    "with open(\"../keras_models/dist_dur_dnn_model_{}.json\".format(time_stamp), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "dist_dur_dnn_model.save_weights(\"../keras_models/dist_dur_dnn_model_{}.h5\".format(time_stamp))\n",
    "print(\"Model saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972296/972296 [==============================] - 2s 2us/step\n",
      "[global_loss, loss, loss_aux_distance] =\n",
      "\t[0.0018564019432673138, 0.001596615743068656, 0.00025978620108731143]\n",
      "[mape, mae, mare] =\n",
      "\t[27.85478061452957, 0.025526032139172202, 21.05401049996036]\n",
      "[mape_aux_distance, mae_aux_distance, mare_aux_distance] =\n",
      "\t[13.769162840300085, 0.00745008761960985, 9.882768488209251]\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION ON TEST DATA\n",
    "#score = model.evaluate(test_input, test_output[:,0], batch_size=BATCH_SIZE)\n",
    "\n",
    "score = dist_dur_dnn_model.evaluate(test_input[:,COLS], [test_output[:,0],test_output[:,1]], batch_size=BATCH_SIZE)\n",
    "\n",
    "# Single task\n",
    "#print('[LOSS, MAPE, MAE, MARE] =', score)\n",
    "\n",
    "# Two tasks\n",
    "print('[global_loss, loss, loss_aux_distance] =', end='\\n\\t')\n",
    "print(score[:3])\n",
    "print('[mape, mae, mare] =', end='\\n\\t')\n",
    "print(score[3:6])\n",
    "print('[mape_aux_distance, mae_aux_distance, mare_aux_distance] =', end='\\n\\t')\n",
    "print(score[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multitask_model(alpha = 0):\n",
    "    \n",
    "    input_layer = Input(shape=(N_FEATS,))\n",
    "    \n",
    "    hidden_layer = Dense(100, name = 'shared_dense1', activation  = 'relu'))(input_layer)\n",
    "    hidden_layer = Dense(100, name = 'shared_dense2', activation  = 'relu')(hidden_layer)\n",
    "    hidden_layer = Dense(200, name = 'shared_dense3', activation  = 'relu')(hidden_layer)\n",
    "    hidden_layer = Dense(300, name = 'shared_dense4', activation  = 'relu')(hidden_layer)\n",
    "    \n",
    "    # Task 1\n",
    "#    hidden1_layer = Dense(300, name = 't1_dense1', activation  = 'relu')(hidden_layer) # NEW LAYER NEW\n",
    "#    hidden1_layer = Dense(200, name = 't1_dense2', activation  = 'relu')(hidden_layer) # NEW LAYER\n",
    "    hidden1_layer = Dense(100, name = 't1_dense3', activation  = 'relu')(hidden_layer)\n",
    "    hidden1_layer = Dense( 40, name = 't1_dense4', activation  = 'relu')(hidden1_layer)\n",
    "    output1_layer = Dense(  1, name = 'duration')(hidden1_layer)\n",
    "    \n",
    "#    # Task 2\n",
    "#     hidden2_layer = Dense(100, name = 't2_dense1', activation  = 'relu')(hidden_layer)\n",
    "#     hidden2_layer = Dense( 40, name = 't2_dense2', activation  = 'relu')(hidden2_layer)\n",
    "#     output2_layer = Dense(  1, name = 'distance')(hidden2_layer)\n",
    "#\n",
    "#     model = Model(inputs=input_layer, outputs=[output1_layer, output2_layer])\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output1_layer)\n",
    "\n",
    "    opt = optimizers.Adam(lr=0.001)\n",
    "    \n",
    "#     LOSS_WEIGHTS = [1,      # MAIN TASK\n",
    "#                     alpha]  # AUXILIARY TASK\n",
    "\n",
    "#     model.compile(loss=['mse', 'mse'],\n",
    "#                   optimizer=opt,\n",
    "#                   metrics=[mape, mae, mare],\n",
    "#                   loss_weights=LOSS_WEIGHTS)\n",
    "    \n",
    "    model.compile(loss=huber_loss,\n",
    "                  optimizer=opt,\n",
    "                  metrics=[mape, mae, mare])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
