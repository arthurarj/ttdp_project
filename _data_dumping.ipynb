{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils/utils_data_cleaning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded with 50000 entries and 10 columns\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "df = load_taxi_data_chunk(chunk=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump it to a binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.94 ms, sys: 8 ms, total: 14.9 ms\n",
      "Wall time: 268 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pkl.dump(df, open('file.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read it back "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 3.67 ms, total: 3.67 ms\n",
      "Wall time: 3.94 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = pkl.load(open('file.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Loading the data using pickle, from a binary file, is much faster than doing from the .csv file directly.\n",
    "\n",
    "Just delete the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('file.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Generate pkl files from csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original csv file has 131165043 (**~130M**) rows. With a chunkesiz of **50k**, we should **2624 chunks**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2624"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size = 50000\n",
    "chunk_number = int(131165043 / chunk_size + 1)\n",
    "chunk_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that it takes 25 seconds to load one chunk with that size, the total would take **18 hours**. \n",
    "\n",
    "To avoid that for now, let's load a smaller number of chunks (e.g. 10). We can load more later using the parameter *skiprows*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_to_skip = []#[i for i in range(1, 1 + 100 * 50000)]\n",
    "chunks_to_load = 10\n",
    "start = 1\n",
    "rows_to_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 10/2624 \n",
      "Size reduction from 50000 to 48822 (1178 samples dropped for missing data)\n",
      "Size reduction from 48822 to 48752 (70 samples dropped for having longer duration than 7200 seconds)\n",
      "Size reduction from 48752 to 48721 (31 samples dropped for having outside the region of interest)\n",
      "Size reduction from 48721 to 48621 (100 samples dropped for being invalid)\n",
      "Final chunk size is 48621 (1379 dropped).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = start\n",
    "for data_chunk in pd.read_csv('../data/2016_Yellow_Taxi_Trip_Data.csv', chunksize=50000, skiprows=rows_to_skip, parse_dates=date_columns):\n",
    "    \n",
    "    clear_output()\n",
    "    print(\"\\rChunk {0}/{1} \".format(i, chunk_number))    \n",
    "    \n",
    "    data_chunk.drop(columns_to_drop, axis=1, inplace=True)\n",
    "    data_chunk.rename(columns_to_rename,axis=1, inplace=True)\n",
    "    data_chunk['duration'] = data_chunk.apply(lambda r: (r['do_t'] - r['pu_t']).seconds, axis=1)\n",
    "    data_chunk['vec_dist'] = data_chunk.apply(lambda s : geopy.distance.geodesic((s.pu_lat, s.pu_lon),(s.do_lat, s.do_lon)).miles, axis=1)\n",
    "    data_chunk['trip_ratio'] = data_chunk.trip_dist / data_chunk.vec_dist\n",
    "    \n",
    "    # Cleaning up\n",
    "    prior_size = data_chunk.shape[0]\n",
    "    handle_missing_data(data_chunk)\n",
    "    handle_duration_outliers(data_chunk, 7200)\n",
    "    handle_spatial_outliers(data_chunk)\n",
    "    handle_invalid_trips(data_chunk)\n",
    "    \n",
    "    # Dump it\n",
    "    pkl.dump(data_chunk, open('../data/bin_chunks/ttd_chunk_{0}.pkl'.format(i), 'wb'))\n",
    "\n",
    "    print(\"Final chunk size is {0} ({1} dropped).\\n\".format(data_chunk.shape[0], prior_size - data_chunk.shape[0]), end='\\n')\n",
    "    \n",
    "    i = i + 1\n",
    "    if i - start + 1 > chunks_to_load:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test one of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pu_t</th>\n",
       "      <th>do_t</th>\n",
       "      <th>trip_dist</th>\n",
       "      <th>pu_lon</th>\n",
       "      <th>pu_lat</th>\n",
       "      <th>do_lon</th>\n",
       "      <th>do_lat</th>\n",
       "      <th>duration</th>\n",
       "      <th>vec_dist</th>\n",
       "      <th>trip_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200000</th>\n",
       "      <td>2016-02-26 09:05:13</td>\n",
       "      <td>2016-02-26 09:18:37</td>\n",
       "      <td>1.35</td>\n",
       "      <td>-73.978851</td>\n",
       "      <td>40.762100</td>\n",
       "      <td>-73.991226</td>\n",
       "      <td>40.750309</td>\n",
       "      <td>804</td>\n",
       "      <td>1.040968</td>\n",
       "      <td>1.296870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200001</th>\n",
       "      <td>2016-02-03 23:45:23</td>\n",
       "      <td>2016-02-04 00:03:34</td>\n",
       "      <td>4.16</td>\n",
       "      <td>-73.993233</td>\n",
       "      <td>40.755428</td>\n",
       "      <td>-73.945961</td>\n",
       "      <td>40.775242</td>\n",
       "      <td>1091</td>\n",
       "      <td>2.831954</td>\n",
       "      <td>1.468950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200002</th>\n",
       "      <td>2016-02-05 12:02:55</td>\n",
       "      <td>2016-02-05 12:09:11</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-73.978020</td>\n",
       "      <td>40.786503</td>\n",
       "      <td>-73.986504</td>\n",
       "      <td>40.779713</td>\n",
       "      <td>376</td>\n",
       "      <td>0.646173</td>\n",
       "      <td>1.238058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200003</th>\n",
       "      <td>2016-02-08 17:25:44</td>\n",
       "      <td>2016-02-08 17:34:07</td>\n",
       "      <td>1.23</td>\n",
       "      <td>-73.967323</td>\n",
       "      <td>40.763527</td>\n",
       "      <td>-73.978668</td>\n",
       "      <td>40.747883</td>\n",
       "      <td>503</td>\n",
       "      <td>1.232742</td>\n",
       "      <td>0.997776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200004</th>\n",
       "      <td>2016-02-10 10:52:41</td>\n",
       "      <td>2016-02-10 11:05:29</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-73.996033</td>\n",
       "      <td>40.732567</td>\n",
       "      <td>-73.986298</td>\n",
       "      <td>40.734493</td>\n",
       "      <td>768</td>\n",
       "      <td>0.527994</td>\n",
       "      <td>1.515167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      pu_t                do_t  trip_dist     pu_lon  \\\n",
       "200000 2016-02-26 09:05:13 2016-02-26 09:18:37       1.35 -73.978851   \n",
       "200001 2016-02-03 23:45:23 2016-02-04 00:03:34       4.16 -73.993233   \n",
       "200002 2016-02-05 12:02:55 2016-02-05 12:09:11       0.80 -73.978020   \n",
       "200003 2016-02-08 17:25:44 2016-02-08 17:34:07       1.23 -73.967323   \n",
       "200004 2016-02-10 10:52:41 2016-02-10 11:05:29       0.80 -73.996033   \n",
       "\n",
       "           pu_lat     do_lon     do_lat  duration  vec_dist  trip_ratio  \n",
       "200000  40.762100 -73.991226  40.750309       804  1.040968    1.296870  \n",
       "200001  40.755428 -73.945961  40.775242      1091  2.831954    1.468950  \n",
       "200002  40.786503 -73.986504  40.779713       376  0.646173    1.238058  \n",
       "200003  40.763527 -73.978668  40.747883       503  1.232742    0.997776  \n",
       "200004  40.732567 -73.986298  40.734493       768  0.527994    1.515167  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl.load(open('../data/bin_chunks/ttd_chunk_5.pkl', 'rb')).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
