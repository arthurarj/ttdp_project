{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (48605, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pu_t</th>\n",
       "      <th>do_t</th>\n",
       "      <th>trip_dist</th>\n",
       "      <th>pu_lon</th>\n",
       "      <th>pu_lat</th>\n",
       "      <th>do_lon</th>\n",
       "      <th>do_lat</th>\n",
       "      <th>duration</th>\n",
       "      <th>vec_dist</th>\n",
       "      <th>trip_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-16 19:56:06</td>\n",
       "      <td>2016-02-16 20:10:46</td>\n",
       "      <td>8.53</td>\n",
       "      <td>-73.995750</td>\n",
       "      <td>40.764488</td>\n",
       "      <td>-73.926292</td>\n",
       "      <td>40.867458</td>\n",
       "      <td>880</td>\n",
       "      <td>7.983998</td>\n",
       "      <td>1.068387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-11 10:23:41</td>\n",
       "      <td>2016-02-11 10:45:04</td>\n",
       "      <td>1.95</td>\n",
       "      <td>-73.994110</td>\n",
       "      <td>40.751068</td>\n",
       "      <td>-73.993401</td>\n",
       "      <td>40.736019</td>\n",
       "      <td>1283</td>\n",
       "      <td>1.039087</td>\n",
       "      <td>1.876648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-21 14:21:57</td>\n",
       "      <td>2016-02-21 14:30:07</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-73.973160</td>\n",
       "      <td>40.752728</td>\n",
       "      <td>-73.982178</td>\n",
       "      <td>40.756962</td>\n",
       "      <td>490</td>\n",
       "      <td>0.556130</td>\n",
       "      <td>0.899070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-11 22:51:59</td>\n",
       "      <td>2016-02-11 22:57:41</td>\n",
       "      <td>1.30</td>\n",
       "      <td>-73.991280</td>\n",
       "      <td>40.744808</td>\n",
       "      <td>-73.985909</td>\n",
       "      <td>40.731178</td>\n",
       "      <td>342</td>\n",
       "      <td>0.981839</td>\n",
       "      <td>1.324045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-13 18:32:08</td>\n",
       "      <td>2016-02-13 18:43:51</td>\n",
       "      <td>1.50</td>\n",
       "      <td>-73.992897</td>\n",
       "      <td>40.741280</td>\n",
       "      <td>-73.975967</td>\n",
       "      <td>40.748734</td>\n",
       "      <td>703</td>\n",
       "      <td>1.026608</td>\n",
       "      <td>1.461123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pu_t                do_t  trip_dist     pu_lon     pu_lat  \\\n",
       "0 2016-02-16 19:56:06 2016-02-16 20:10:46       8.53 -73.995750  40.764488   \n",
       "1 2016-02-11 10:23:41 2016-02-11 10:45:04       1.95 -73.994110  40.751068   \n",
       "2 2016-02-21 14:21:57 2016-02-21 14:30:07       0.50 -73.973160  40.752728   \n",
       "3 2016-02-11 22:51:59 2016-02-11 22:57:41       1.30 -73.991280  40.744808   \n",
       "4 2016-02-13 18:32:08 2016-02-13 18:43:51       1.50 -73.992897  40.741280   \n",
       "\n",
       "      do_lon     do_lat  duration  vec_dist  trip_ratio  \n",
       "0 -73.926292  40.867458       880  7.983998    1.068387  \n",
       "1 -73.993401  40.736019      1283  1.039087    1.876648  \n",
       "2 -73.982178  40.756962       490  0.556130    0.899070  \n",
       "3 -73.985909  40.731178       342  0.981839    1.324045  \n",
       "4 -73.975967  40.748734       703  1.026608    1.461123  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_chunks = 1\n",
    "chunks = [pkl.load(open('data/bin_chunks/ttd_chunk_{0}.pkl'.format(i), 'rb')) for i in range(1, n_chunks + 1)]\n",
    "dataset = pd.concat(chunks)\n",
    "print(\"Data shape:\", dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_data = np.array(pd.concat((dataset.pu_lat, dataset.do_lat))).reshape(-1,1)\n",
    "lon_data = np.array(pd.concat((dataset.pu_lon, dataset.do_lon))).reshape(-1,1)\n",
    "dur_data = np.array(dataset.duration.astype(float)).reshape(-1,1)\n",
    "    \n",
    "scaler_type = 'StandardScaler' # Other options: MinMaxScaler\n",
    "lat_scaler = getattr(preprocessing, scaler_type)()\n",
    "lon_scaler = getattr(preprocessing, scaler_type)()\n",
    "out_scaler = getattr(preprocessing, scaler_type)()\n",
    "\n",
    "lat_scaler.fit(lat_data);\n",
    "lon_scaler.fit(lon_data);\n",
    "out_scaler.fit(dur_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((lat_scaler.transform(dataset[['pu_lat','do_lat',]]),\n",
    "               lon_scaler.transform(dataset[['pu_lon','do_lon',]])))\n",
    "y = out_scaler.transform(dur_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "test_size = len(y_test)\n",
    "train_size = len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 45\n",
      "Trainable params: 45\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Dense(4, activation  = tf.nn.relu,\n",
    "                           input_shape = (X_train.shape[1],)),\n",
    "    keras.layers.Dense(4, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.train.RMSPropOptimizer(0.001)\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/6\n",
      "27218/27218 [==============================] - 1s 36us/step - loss: 0.3222 - mean_absolute_error: 0.3840 - val_loss: 0.3441 - val_mean_absolute_error: 0.3954\n",
      "{'val_loss': 0.3441006693395072, 'val_mean_absolute_error': 0.3954461666567198, 'loss': 0.3221985506611976, 'mean_absolute_error': 0.3839895018767238}\n"
     ]
    }
   ],
   "source": [
    "EPOCHS =6\n",
    "    \n",
    "# Store training stats\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS,\n",
    "                    validation_split=0.2, verbose=1, callbacks=[PrintDot()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
